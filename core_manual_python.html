<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
    "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
  <link href="bootstrap/bootstrap.css" type="text/css" rel="stylesheet"/>

  <link href="google-code-prettify/prettify.css" type="text/css" rel="stylesheet"/>
  <script type="text/javascript" src="google-code-prettify/prettify.js"></script>
  <link href="css/vertx.css" type="text/css" rel="stylesheet"/>
  <link href="css/sunburst.css" type="text/css" rel="stylesheet"/>
  <title>Vert.x Python API Manual</title>
  <script>
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-30144458-1']);
    _gaq.push(['_trackPageview']);
    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
</head>

<body onload="prettyPrint()">

<div class="navbar navbar-fixed-top">
  <div class="navbar-inner">
    <div class="container">

      <a class="btn btn-navbar" data-toggle="collapse"
         data-target=".nav-collapse">
        <span class="i-bar"></span>
        <span class="i-bar"></span>
        <span class="i-bar"></span>
      </a>

      <a class="brand" href="/">vert.x</a>

      <div class="nav-collapse">
        <ul class="nav">
          <li class="active"><a href="/">Home</a></li>
          <li><a href="downloads.html">Download</a></li>
          <li><a href="install.html">Install</a></li>
          <li><a href="tutorials.html">Tutorials</a></li>
          <li><a href="examples.html">Examples</a></li>
          <li><a href="docs.html">Documentation</a></li>
          <li><a href="https://github.com/purplefox/vert.x">Source</a></li>
          <li><a href="http://groups.google.com/group/vertx">Google Group</a></li>
          <li><a href="community.html">Community</a></li>
          <li><a href="http://vertxproject.wordpress.com/">Blog</a></li>
        </ul>
      </div>
    </div>
  </div>
</div>

<div class="container">

  <div class="row">
    <div class="span12">
      <div class="well">
        <h1 style="font-size: 35px;">Python API Manual</h1>
      </div>
    </div>
  </div>

  <div class="row">
    <div class="span12">
      <div class="well">
<div>


<div class="toc">
<ul>
<li><a href="#writing-verticles">Writing Verticles</a><ul>
<li><a href="#accessing-the-vertx-api">Accessing the Vert.x API</a></li>
<li><a href="#verticle-clean-up">Verticle clean-up</a></li>
<li><a href="#getting-configuration-in-a-verticle">Getting Configuration in a Verticle</a></li>
<li><a href="#logging-from-a-verticle">Logging from a Verticle</a></li>
</ul>
</li>
<li><a href="#deploying-and-undeploying-verticles-programmatically">Deploying and Undeploying Verticles Programmatically</a><ul>
<li><a href="#deploying-a-simple-verticle">Deploying a simple verticle</a></li>
<li><a href="#deploying-a-module-programmatically">Deploying a module programmatically</a></li>
<li><a href="#passing-configuration-to-a-verticle-programmatically">Passing configuration to a verticle programmatically</a></li>
<li><a href="#using-a-verticle-to-co-ordinate-loading-of-an-application">Using a Verticle to co-ordinate loading of an application</a></li>
<li><a href="#specifying-number-of-instances">Specifying number of instances</a></li>
<li><a href="#getting-notified-when-deployment-is-complete">Getting Notified when Deployment is complete</a></li>
<li><a href="#deploying-worker-verticles">Deploying Worker Verticles</a></li>
<li><a href="#undeploying-a-verticle">Undeploying a Verticle</a></li>
</ul>
</li>
<li><a href="#the-event-bus">The Event Bus</a><ul>
<li><a href="#the-theory">The Theory</a><ul>
<li><a href="#addressing">Addressing</a></li>
<li><a href="#handlers">Handlers</a></li>
<li><a href="#sending-messages">Sending messages</a></li>
</ul>
</li>
<li><a href="#event-bus-api">Event Bus API</a><ul>
<li><a href="#registering-and-unregistering-handlers">Registering and Unregistering Handlers</a></li>
<li><a href="#sending-messages_1">Sending messages</a></li>
<li><a href="#replying-to-messages">Replying to messages</a></li>
</ul>
</li>
<li><a href="#distributed-event-bus">Distributed event bus</a></li>
</ul>
</li>
<li><a href="#shared-data">Shared Data</a><ul>
<li><a href="#shared-hashes">Shared Hashes</a></li>
<li><a href="#shared-sets">Shared Sets</a></li>
</ul>
</li>
<li><a href="#buffers">Buffers</a><ul>
<li><a href="#creating-buffers">Creating Buffers</a></li>
<li><a href="#writing-to-a-buffer">Writing to a Buffer</a><ul>
<li><a href="#appending-to-a-buffer">Appending to a Buffer</a></li>
<li><a href="#random-access-buffer-writes">Random access buffer writes</a></li>
</ul>
</li>
<li><a href="#reading-from-a-buffer">Reading from a Buffer</a></li>
<li><a href="#other-buffer-methods">Other buffer methods:</a></li>
</ul>
</li>
<li><a href="#delayed-and-periodic-tasks">Delayed and Periodic Tasks</a><ul>
<li><a href="#one-shot-timers">One-shot Timers</a></li>
<li><a href="#periodic-timers">Periodic Timers</a></li>
<li><a href="#cancelling-timers">Cancelling timers</a></li>
</ul>
</li>
<li><a href="#writing-tcp-servers-and-clients">Writing TCP Servers and Clients</a><ul>
<li><a href="#net-server">Net Server</a><ul>
<li><a href="#creating-a-net-server">Creating a Net Server</a></li>
<li><a href="#start-the-server-listening">Start the Server Listening</a></li>
<li><a href="#getting-notified-of-incoming-connections">Getting Notified of Incoming Connections</a></li>
<li><a href="#closing-a-net-server">Closing a Net Server</a></li>
<li><a href="#netserver-properties">NetServer Properties</a></li>
<li><a href="#handling-data">Handling Data</a><ul>
<li><a href="#reading-data-from-the-socket">Reading Data from the Socket</a></li>
<li><a href="#writing-data-to-a-socket">Writing Data to a Socket</a></li>
</ul>
</li>
<li><a href="#closing-a-socket">Closing a socket</a></li>
<li><a href="#closed-handler">Closed Handler</a></li>
<li><a href="#exception-handler">Exception handler</a></li>
<li><a href="#read-and-write-streams">Read and Write Streams</a></li>
</ul>
</li>
<li><a href="#scaling-tcp-servers">Scaling TCP Servers</a></li>
<li><a href="#netclient">NetClient</a><ul>
<li><a href="#creating-a-net-client">Creating a Net Client</a></li>
<li><a href="#making-a-connection">Making a Connection</a></li>
<li><a href="#catching-exceptions-on-the-net-client">Catching exceptions on the Net Client</a></li>
<li><a href="#configuring-reconnection">Configuring Reconnection</a></li>
<li><a href="#netclient-properties">NetClient Properties</a></li>
</ul>
</li>
<li><a href="#ssl-servers">SSL Servers</a></li>
<li><a href="#ssl-clients">SSL Clients</a></li>
</ul>
</li>
<li><a href="#flow-control-streams-and-pumps">Flow Control - Streams and Pumps</a><ul>
<li><a href="#readstream">ReadStream</a></li>
<li><a href="#writestream">WriteStream</a></li>
<li><a href="#pump">Pump</a></li>
</ul>
</li>
<li><a href="#writing-http-servers-and-clients">Writing HTTP Servers and Clients</a><ul>
<li><a href="#writing-http-servers">Writing HTTP servers</a><ul>
<li><a href="#creating-an-http-server">Creating an HTTP Server</a></li>
<li><a href="#start-the-server-listening_1">Start the Server Listening</a></li>
<li><a href="#getting-notified-of-incoming-requests">Getting Notified of Incoming Requests</a></li>
<li><a href="#handling-http-requests">Handling HTTP Requests</a><ul>
<li><a href="#request-method">Request Method</a></li>
<li><a href="#request-uri">Request URI</a></li>
<li><a href="#request-path">Request Path</a></li>
<li><a href="#request-query">Request Query</a></li>
<li><a href="#request-headers">Request Headers</a></li>
<li><a href="#request-params">Request params</a></li>
<li><a href="#reading-data-from-the-request-body">Reading Data from the Request Body</a></li>
</ul>
</li>
<li><a href="#http-server-responses">HTTP Server Responses</a></li>
<li><a href="#setting-status-code-and-message">Setting Status Code and Message</a><ul>
<li><a href="#writing-http-responses">Writing HTTP responses</a></li>
<li><a href="#ending-http-responses">Ending HTTP responses</a></li>
<li><a href="#closing-the-underlying-connection">Closing the underlying connection</a></li>
<li><a href="#response-headers">Response headers</a></li>
<li><a href="#chunked-http-responses-and-trailers">Chunked HTTP Responses and Trailers</a></li>
</ul>
</li>
<li><a href="#serving-files-directly-from-disk">Serving files directly from disk</a></li>
<li><a href="#pumping-responses">Pumping Responses</a></li>
</ul>
</li>
<li><a href="#writing-http-clients">Writing HTTP Clients</a><ul>
<li><a href="#creating-an-http-client">Creating an HTTP Client</a></li>
<li><a href="#pooling-and-keep-alive">Pooling and Keep Alive</a></li>
<li><a href="#closing-the-client">Closing the client</a></li>
<li><a href="#making-requests">Making Requests</a><ul>
<li><a href="#writing-to-the-request-body">Writing to the request body</a></li>
<li><a href="#ending-http-requests">Ending HTTP requests</a></li>
<li><a href="#writing-request-headers">Writing Request Headers</a></li>
<li><a href="#http-chunked-requests">HTTP chunked requests</a></li>
</ul>
</li>
<li><a href="#http-client-responses">HTTP Client Responses</a><ul>
<li><a href="#reading-data-from-the-response-body">Reading Data from the Response Body</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#pumping-requests-and-responses">Pumping Requests and Responses</a><ul>
<li><a href="#100-continue-handling">100-Continue Handling</a></li>
</ul>
</li>
<li><a href="#https-servers">HTTPS Servers</a></li>
<li><a href="#https-clients">HTTPS Clients</a></li>
<li><a href="#scaling-http-servers">Scaling HTTP servers</a></li>
</ul>
</li>
<li><a href="#routing-http-requests-with-pattern-matching">Routing HTTP requests with Pattern Matching</a><ul>
<li><a href="#specifying-matches">Specifying matches.</a></li>
<li><a href="#extracting-parameters-from-the-path">Extracting parameters from the path</a></li>
<li><a href="#extracting-params-using-regular-expressions">Extracting params using Regular Expressions</a></li>
<li><a href="#handling-requests-where-nothing-matches">Handling requests where nothing matches</a></li>
</ul>
</li>
<li><a href="#websockets">WebSockets</a><ul>
<li><a href="#websockets-on-the-server">WebSockets on the server</a><ul>
<li><a href="#reading-from-and-writing-to-websockets">Reading from and Writing to WebSockets</a></li>
<li><a href="#rejecting-websockets">Rejecting WebSockets</a></li>
</ul>
</li>
<li><a href="#websockets-on-the-http-client">WebSockets on the HTTP client</a></li>
<li><a href="#websockets-in-the-browser">WebSockets in the browser</a></li>
<li><a href="#routing-websockets-with-pattern-matching">Routing WebSockets with Pattern Matching</a></li>
</ul>
</li>
<li><a href="#sockjs">SockJS</a><ul>
<li><a href="#sockjs-server">SockJS Server</a></li>
<li><a href="#reading-and-writing-data-from-a-sockjs-server">Reading and writing data from a SockJS server</a></li>
<li><a href="#sockjs-client">SockJS client</a></li>
</ul>
</li>
<li><a href="#sockjs-eventbus-bridge">SockJS - EventBus Bridge</a><ul>
<li><a href="#setting-up-the-bridge">Setting up the Bridge</a></li>
<li><a href="#using-the-event-bus-from-client-side-javascript">Using the Event Bus from client side JavaScript</a></li>
<li><a href="#securing-the-bridge">Securing the Bridge</a></li>
<li><a href="#messages-that-require-authorisation">Messages that require authorisation</a></li>
</ul>
</li>
<li><a href="#file-system">File System</a><ul>
<li><a href="#synchronous-forms">Synchronous forms</a></li>
<li><a href="#copy">copy</a></li>
<li><a href="#move">move</a></li>
<li><a href="#truncate">truncate</a></li>
<li><a href="#chmod">chmod</a></li>
<li><a href="#props">props</a></li>
<li><a href="#lprops">lprops</a></li>
<li><a href="#link">link</a></li>
<li><a href="#symlink">symlink</a></li>
<li><a href="#unlink">unlink</a></li>
<li><a href="#read_sym_link">read_sym_link</a></li>
<li><a href="#delete">delete</a></li>
<li><a href="#mkdir">mkdir</a></li>
<li><a href="#read_dir">read_dir</a></li>
<li><a href="#read_file_as_buffer">read_file_as_buffer</a></li>
<li><a href="#write_buffer_to_file">write_buffer_to_file</a></li>
<li><a href="#create_file">create_file</a></li>
<li><a href="#exists">exists?</a></li>
<li><a href="#fs_props">fs_props</a></li>
<li><a href="#open">open</a></li>
<li><a href="#asyncfile">AsyncFile</a><ul>
<li><a href="#random-access-writes">Random access writes</a></li>
<li><a href="#random-access-reads">Random access reads</a></li>
<li><a href="#flushing-data-to-underlying-storage">Flushing data to underlying storage.</a></li>
<li><a href="#using-asyncfile-as-readstream-and-writestream">Using AsyncFile as ReadStream and WriteStream</a></li>
<li><a href="#closing-an-asyncfile">Closing an AsyncFile</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<h1 id="writing-verticles">Writing Verticles</h1><br/>
<p>We previously discussed how a verticle is the unit of deployment in vert.x. Let's look in more detail about how to write a verticle.</p>
<p>As an example we'll write a simple TCP echo server. The server just accepts connections and any data received by it is echoed back on the connection.</p>
<p>Copy the following into a text editor and save it as <code>server.py</code></p>
<pre class="prettyprint">import vertx
from core.streams import Pump

server = vertx.create_net_server()
@server.connect_handler
def connect_handler(socket):
    Pump(socket, server).start()
server.listen(1234, 'localhost')

def vertx_stop():
    server.close()
</pre>
<p>Now, go to the directory where you saved the file and type</p>
<pre class="prettyprint">vertx run server.py
</pre>
<p>The server will now be running. Connect to it using telnet:</p>
<pre class="prettyprint">telnet localhost 1234
</pre>
<p>And notice how data you send (and hit enter) is echoed back to you.</p>
<p>Congratulations! You've written your first verticle.</p>
<h2 id="accessing-the-vertx-api">Accessing the Vert.x API</h2><br/>
<p>If you want to access the vert.x core API from within your verticle (which you almost certainly want to do), you need to import it with <code>import vertx</code> at the top of your script. Normally this will be the first thing at the top of your verticle main.</p>
<p>This will import the package <code>vertx</code>. The <code>vertx</code> package contains some of the methods that make up the vert.x core API. Other methods are available in the <code>core</code> packages.</p>
<h2 id="verticle-clean-up">Verticle clean-up</h2><br/>
<p>Servers, clients and event bus handlers will be automatically closed when the verticles is stopped, however if you need to provide any custom clean-up code when the verticle is stopped you can provide a <code>vertx_stop</code> top-level method. Vert.x will then call this when the verticle is stopped. </p>
<h2 id="getting-configuration-in-a-verticle">Getting Configuration in a Verticle</h2><br/>
<p>If JSON configuration has been passed when deploying a verticle from either the command line using <code>vertx run</code> and specifying a configuration file with <code>-conf &lt;config_file&gt;</code>, or when deploying programmatically, that configuration is available to the verticle using the <code>vertx.config</code> method. For example:</p>
<pre class="prettyprint">import vertx

config = vertx.config()

# Do something with config

print "number of wibbles is %s" % str(config.wibble_number)
</pre>
<p>The config returned is a Python dict. You can use this object to configure the verticle. Allowing verticles to be configured in a consistent way like this allows configuration to be easily passed to them irrespective of the language.</p>
<h2 id="logging-from-a-verticle">Logging from a Verticle</h2><br/>
<p>Each verticle is given its own logger. To get a reference to it invoke the <code>vertx.get_logger</code> method:</p>
<pre class="prettyprint">import vertx

var logger = vertx.get_logger()

logger.info("I am logging something")
</pre>
<p>The logger has the functions:</p>
<ul>
<li>trace</li>
<li>debug</li>
<li>info</li>
<li>warn</li>
<li>error</li>
<li>fatal</li>
</ul>
<p>Which have the normal meanings you would expect.</p>
<p>The log files by default go in a file called <code>vertx.log</code> in the system temp directory. On my Linux box this is <code>\tmp</code>.</p>
<p>For more information on configuring logging, please see the main manual.</p>
<h1 id="deploying-and-undeploying-verticles-programmatically">Deploying and Undeploying Verticles Programmatically</h1><br/>
<p>You can deploy and undeploy verticles programmatically from inside another verticle. Any verticles deployed programmatically inherit the path of the parent verticle.</p>
<h2 id="deploying-a-simple-verticle">Deploying a simple verticle</h2><br/>
<p>To deploy a verticle programmatically call the function <code>vertx.deploy_verticle</code>. The return value of <code>vertx.deploy_verticle</code> is the unique id of the deployment, which can be used later to undeploy the verticle.</p>
<p>To deploy a single instance of a verticle :</p>
<pre class="prettyprint">vertx.deploy_verticle('my_verticle.py')
</pre>
<h2 id="deploying-a-module-programmatically">Deploying a module programmatically</h2><br/>
<p>You should use <code>deploy_module</code> to deploy a module, for example:</p>
<pre class="prettyprint">vertx.deploy_module('vertx.mailer-v1.0', config)
</pre>
<p>Would deploy an instance of the <code>vertx.mailer</code> module with the specified configuration. Please see the modules manual
 for more information about modules.</p>
<h2 id="passing-configuration-to-a-verticle-programmatically">Passing configuration to a verticle programmatically</h2><br/>
<p>JSON configuration can be passed to a verticle that is deployed programmatically. Inside the deployed verticle the configuration is accessed with the <code>vertx.config</code> function. For example:</p>
<pre class="prettyprint">config = { 'name': 'foo', 'age': 234 }
vertx.deploy_verticle('my_verticle.py', config)
</pre>
<p>Then, in <code>my_verticle.py</code> you can access the config via <code>vertx.config</code> method as previously explained.</p>
<h2 id="using-a-verticle-to-co-ordinate-loading-of-an-application">Using a Verticle to co-ordinate loading of an application</h2><br/>
<p>If you have an application that is composed of multiple verticles that all need to be started at application start-up, then you can use another verticle that maintains the application configuration and starts all the other verticles. You can think of this as your application starter verticle.</p>
<p>For example, you could create a verticle <code>app.py</code> as follows:</p>
<pre class="prettyprint">import vertx

# Application config
appConfig = {
    'verticle1_config' : {
        # Config for verticle1
    },
    'verticle2_config' : {
        # Config for verticle2
    },
    'verticle3_config' : {
        # Config for verticle3
    },
    'verticle4_config' : {
        # Config for verticle4
    },
    'verticle5_config' : {
        # Config for verticle5
    }
}

# Start the verticles that make up the app

vertx.deploy_verticle("verticle1.py", appConfig["verticle1_config"])
vertx.deploy_verticle("verticle2.py", appConfig["verticle2_config"], 5)
vertx.deploy_verticle("verticle3.py", appConfig["verticle3_config"])
vertx.deploy_worker_verticle("verticle4.py", appConfig["verticle4_config"])
vertx.deploy_worker_verticle("verticle5.py", appConfig["verticle5_config"], 10)
</pre>
<p>Then you can start your entire application by simply running:</p>
<pre class="prettyprint">vertx run app.py
</pre>
<h2 id="specifying-number-of-instances">Specifying number of instances</h2><br/>
<p>By default, when you deploy a verticle only one instance of the verticle is deployed. If you want more than one instance to be deployed, e.g. so you can scale over your cores better, you can specify the number of instances in the third parameter to <code>deploy_verticle</code>:</p>
<pre class="prettyprint">vertx.deploy_verticle('my_verticle.py', None, 10)
</pre>
<p>or</p>
<pre class="prettyprint">vertx.deploy_verticle('my_verticle.py', instances=10)
</pre>
<p>The above examples would both deploy 10 instances.</p>
<h2 id="getting-notified-when-deployment-is-complete">Getting Notified when Deployment is complete</h2><br/>
<p>The actual verticle deployment is asynchronous and might not complete until some time after the call to <code>deploy_verticle</code> has returned. If you want to be notified when the verticle has completed being deployed, you can pass an handler function to <code>deploy_verticle</code>, which will be called when it's complete:</p>
<pre class="prettyprint">def deploy_handler(dip):
    print "It's been deployed!"
vertx.deploy_verticle('my_verticle.py', None, 10, deploy_handler)
</pre>
<h2 id="deploying-worker-verticles">Deploying Worker Verticles</h2><br/>
<p>The <code>vertx.deploy_verticle</code> method deploys standard (non worker) verticles. If you want to deploy worker verticles use the <code>vertx.deploy_worker_verticle</code> function. This function takes the same parameters as <code>vertx.deploy_verticle</code> with the same meanings.</p>
<h2 id="undeploying-a-verticle">Undeploying a Verticle</h2><br/>
<p>Any verticles that you deploy programmatically from within a verticle and all of their children are automatically undeployed when the parent verticle is undeployed, so in most cases you will not need to undeploy a verticle manually, however if you do want to do this, it can be done by calling the function <code>vertx.undeploy_verticle</code> passing in the deployment id that was sent to the deployment handler function you passed to <code>vertx.deploy_verticle</code></p>
<pre class="prettyprint">def deploy_handler(dip):
    vertx.undeploy_verticle(dip)
vertx.deploy_verticle('my_verticle.py', deploy_handler)
</pre>
<h1 id="the-event-bus">The Event Bus</h1><br/>
<p>The event bus is the nervous system of vert.x.</p>
<p>It allows verticles to communicate with each other irrespective of what language they are written in, and whether they're in the same vert.x instance, or in a different vert.x instance. It even allows client side JavaScript running in a browser to communicate on the same event bus. (More on that later).</p>
<p>It creates a distributed polyglot overlay network spanning multiple server nodes and multiple browsers.</p>
<p>The event bus API is incredibly simple. It basically involves registering handlers, unregistering handlers and sending messages.</p>
<p>First some theory:</p>
<h2 id="the-theory">The Theory</h2><br/>
<h3 id="addressing">Addressing</h3><br/>
<p>Messages are sent on the event bus to an <em>address</em>.</p>
<p>Vert.x doesn't bother with any fancy addressing schemes. In vert.x an address is simply a string, any string is valid. However it is wise to use some kind of scheme, e.g. using periods to demarcate a namespace.</p>
<p>Some examples of valid addresses are <code>europe.news.feed1</code>, <code>acme.games.pacman</code>, <code>sausages</code>, and <code>X</code>.</p>
<h3 id="handlers">Handlers</h3><br/>
<p>A handler is a thing that receives messages from the bus. You register a handler at an address.</p>
<p>The handler will receive any messages that are sent to the address. Many different handlers from the same or different verticles can be registered at the same address. A single handler can be registered by the verticle at many different addresses.</p>
<p>Since many handlers can subscribe to the address, this is an implementation of the messaging pattern called <em>Publish-Subscribe Messaging</em>.</p>
<p>When a message is received in a handler, and has been <em>processed</em>, the receiver can optionally decide to reply to the message. If they do so, and the message was sent specifying a reply handler, that reply handler will be called.</p>
<p>When the reply is received back at the sender, it too can be replied to. This can be repeated ad-infinitum, and allows a dialog to be set-up between two different verticles.</p>
<p>This is a common messaging pattern called the <em>Request-Response</em> pattern.</p>
<h3 id="sending-messages">Sending messages</h3><br/>
<p>You send a message by specifying the address and telling the event bus to send it there. The event bus will then deliver the message to any handlers registered at that address.</p>
<p>If multiple vert.x instances are clustered together, the message will be delivered to any matching handlers irrespective of what vert.x instance they reside on.</p>
<p>As previously mentioned, when sending a message you can specify an optional reply handler which will be invoked once the message has reached a handler and the recipient has replied to it.</p>
<p><em>All messages in the event bus are transient, and in case of failure of all or parts of the event bus, there is a possibility messages will be lost. If your application cares about lost messages, you should code your handlers to be idempotent, and your senders to retry after recovery.</em></p>
<p>If you want to persist your messages you can use a persistent work queue module for that.</p>
<p>Messages that you send on the event bus can be as simple as a string, a number or a boolean. You can also send vert.x buffers or JSON messages.</p>
<p>It's highly recommended you use JSON messages to communicate between verticles. JSON is easy to create and parse in all the languages that vert.x supports.</p>
<h2 id="event-bus-api">Event Bus API</h2><br/>
<p>Let's jump into the API</p>
<h3 id="registering-and-unregistering-handlers">Registering and Unregistering Handlers</h3><br/>
<p>To set a message handler on the address <code>test.address</code>, you call the method <code>register_handler</code> on the <code>EventBus</code> class</p>
<pre class="prettyprint">from core.event_bus import EventBus

def handler(message):
    print "Got message body %s"% message.body
id = EventBus.register_handler('test.address', handler)
</pre>
<p>It's as simple as that. The handler will then receive any messages sent to that address. The object passed into the handler is an instance of class <code>core.Message</code>. The body of the message is available via the <code>body</code> attribute. </p>
<p>The return value of <code>register_handler</code> is a unique handler id which can used later to unregister the handler.</p>
<p>When you register a handler on an address and you're in a cluster it can take some time for the knowledge of that new handler to be propagated across the entire cluster. If you want to be notified when that has completed you can optionally specify a block to the <code>register_handler</code> method as the third argument. This block will then be called once the information has reached all nodes of the cluster. E.g. :</p>
<pre class="prettyprint">from core.event_bus import EventBus

def myHandler(message):
    print 'Yippee! The handler info has been propagated across the cluster'
EventBus.register_handler('test.address', myHandler)
</pre>
<p>To unregister a handler it's just as straightforward. You simply call <code>unregister_handler</code> passing in the id of the handler:</p>
<pre class="prettyprint">EventBus.unregister_handler('test.address', id);
</pre>
<p>As with registering, when you unregister a handler and you're in a cluster it can also take some time for the knowledge of that unregistration to be propagated across the entire to cluster.
If you want your handler to live for the full lifetime of your verticle there is no need to unregister it explicitly - vert.x will automatically unregister any handlers when the verticle is stopped.  </p>
<h3 id="sending-messages_1">Sending messages</h3><br/>
<p>Sending a message is also trivially easy. Just send it specifying the address you want to send it to, for example:</p>
<pre class="prettyprint">from core.event_bus import EventBus

EventBus.send('test.address', 'hello world')
</pre>
<p>That message will then be delivered to any handlers registered against the address <code>test.address</code>. If you are running vert.x in cluster mode then it will also be delivered to any handlers on that address irrespective of what vert.x instance they are in.</p>
<p>The message you send can be any of the following types:</p>
<ul>
<li>number</li>
<li>String</li>
<li>boolean</li>
<li>JSON object</li>
<li>Vert.x Buffer</li>
</ul>
<p>Vert.x buffers and JSON objects are copied before delivery if they are delivered in the same JVM, so different verticles can't access the exact same object instance.</p>
<p>Here are some more examples:</p>
<p>Send some numbers:</p>
<pre class="prettyprint">EventBus.send('test.address', 1234)
EventBus.send('test.address', 3.14159)
</pre>
<p>Send a boolean:</p>
<pre class="prettyprint">EventBus.send('test.address', True)
</pre>
<p>Send a JSON object:</p>
<pre class="prettyprint">myObj = {
  'name' : 'Tim',
  'address' : 'The Moon',
  'age' : 457
}
EventBus.send('test.address', myObj)
</pre>
<p>None messages can also be sent:</p>
<pre class="prettyprint">EventBus.send('test.address', None)
</pre>
<p>It's a good convention to have your verticles communicating using JSON.</p>
<h3 id="replying-to-messages">Replying to messages</h3><br/>
<p>Sometimes after you send a message you want to receive a reply from the recipient. This is known as the <em>request-response pattern</em>.</p>
<p>To do this you send a message, and specify a block as a reply handler. When the receiver receives the message there is a method <code>reply</code> on the <code>Message</code> instance that is passed into the handler.</p>
<p>When this function is invoked it causes a reply to be sent back to the sender where the reply handler is invoked. An example will make this clear:</p>
<p>The receiver:</p>
<pre class="prettyprint">def handler(message):
    print "I received a message %s"% message.body

    # Do some stuff...
    # Now reply to it
    message.reply('This is a reply')

EventBus.registerHandler('test.address', handler)
</pre>
<p>The sender:</p>
<pre class="prettyprint">def reply_handler(message):
     print "I received a reply %s"%message.body     
EventBus.send('test.address', 'This is a message', reply_handler)
</pre>
<p>It is legal also to send an empty reply or None reply.</p>
<p>The replies themselves can also be replied to so you can create a dialog between two different verticles consisting of multiple rounds.</p>
<h2 id="distributed-event-bus">Distributed event bus</h2><br/>
<p>To make each vert.x instance on your network participate on the same event bus, start each vert.x instance with the <code>-cluster</code> command line switch.</p>
<p>See the chapter in the main manual on running vert.x for more information on this.</p>
<p>Once you've done that, any vert.x instances started in cluster mode will merge to form a distributed event bus.</p>
<h1 id="shared-data">Shared Data</h1><br/>
<p>Sometimes it makes sense to allow different verticles instances to share data in a safe way. Vert.x allows simple <em>dict</em> and <em>set</em> data structures to be shared between verticles.</p>
<p>There is a caveat: To prevent issues due to mutable data, vert.x only allows simple immutable types such as number, boolean and string or Buffer to be used in shared data. With a Buffer, it is automatically copied when retrieved from the shared data, so different verticle instances never see the same object instance.</p>
<p>Currently data can only be shared between verticles in the <em>same vert.x instance</em>. In later versions of vert.x we aim to extend this to allow data to be shared by all vert.x instances in the cluster.</p>
<h2 id="shared-hashes">Shared Hashes</h2><br/>
<p>To use a shared hash to share data between verticles first get a reference to the hash, and then we just use standard Hash operations to put and get the data.</p>
<pre class="prettyprint">from core.shared_data import SharedData

hash = SharedData.get_hash('demo.myhash')

hash['some-key'] = 'some-value'
</pre>
<p>And then, in a different verticle:</p>
<pre class="prettyprint">hash = SharedData.get_hash('demo.myhash')

print "value of some-key is %s"% hash['some-key']
</pre>
<p><strong>TODO</strong> More on map API</p>
<h2 id="shared-sets">Shared Sets</h2><br/>
<p>To use a shared set to share data between verticles first get a reference to the set.</p>
<pre class="prettyprint">from core.shared_data import SharedData

set = SharedData.get_set('demo.myset')

set.add('some-value');
</pre>
<p>And then, in a different verticle:</p>
<pre class="prettyprint">set = SharedData.get_set('demo.myset')

# Do something with the set
</pre>
<p><strong>TODO</strong> - More on set API</p>
<p>API - atomic updates etc</p>
<h1 id="buffers">Buffers</h1><br/>
<p>Most data in vert.x is shuffled around using instances of <code>core.buffer.Buffer</code>.</p>
<p>A Buffer represents a sequence of zero or more bytes that can be written to or read from, and which expands automatically as necessary to accomodate any bytes written to it.</p>
<h2 id="creating-buffers">Creating Buffers</h2><br/>
<p>Create an empty buffer</p>
<pre class="prettyprint">from core.buffer import Buffer
buff = Buffer.create()
</pre>
<p>Create a buffer from a String. The String will be encoded in the buffer using UTF-8.</p>
<pre class="prettyprint">buff = Buffer.create_from_str("some-string")
</pre>
<p>Create a buffer from a String: The String will be encoded using the specified encoding, e.g:</p>
<pre class="prettyprint">buff = Buffer.create_from_str("some-string", "UTF-16")
</pre>
<p>Create a buffer with an initial size hint. If you know your buffer will have a certain amount of data written to it you can create the buffer and specify this size. This makes the buffer initially allocate that much memory and is more efficient than the buffer automatically resizing multiple times as data is written to it.</p>
<p>Note that buffers created this way <em>are empty</em>. It does not create a buffer filled with zeros up to the specified size.</p>
<pre class="prettyprint">buff = Buffer.create(100000)
</pre>
<h2 id="writing-to-a-buffer">Writing to a Buffer</h2><br/>
<p>There are two ways to write to a buffer: appending, and random access. In either case buffers will always expand automatically to encompass the bytes. It's not possible to write outside the bounds of the buffer.</p>
<h3 id="appending-to-a-buffer">Appending to a Buffer</h3><br/>
<p>To append to a buffer, you use the <code>append_XXX</code> methods. Append methods exist for appending other buffers, String, Float and FixNum.</p>
<p>When appending a FixNum you have to specify how many bytes you want to append this as in the buffer. Valid values are 1, 2, 4, 8. All FixNums are appended as signed integer values.</p>
<p>When appending a Float you have to specify how many bytes you want to append this as in the buffer. Valid values are 4, 8, representing a single precision 32-bit IEEE 754 and a double precision 64-bit IEEE 754 floating point number respectively.</p>
<p>The return value of the <code>append_XXX</code> methods is the buffer itself, so these can be chained:</p>
<pre class="prettyprint">from core.buffer import Buffer

buff = Buffer.create

buff.append_fixnum(100, 1) # Append a single byte in the buffer
buff.append_fixnum(231243, 8) # Append number as 8 bytes in the buffer
buff.append_str('foo').append_float(23.4232, 4) # Appends can be chained

socket.write_buffer(buff)
</pre>
<p>Appending FixNums:</p>
<pre class="prettyprint">buff.append_fixnum(100, 1)   # Append number as single signed byte

buff.append_fixnum(100, 2)   # Append number as signed integer in two bytes

buff.append_fixnum(100, 4)   # Append number as signed integer in four bytes

buff.append_fixnum(100, 8)   # Append number as signed integer in eight bytes
</pre>
<p>Appending Floats:</p>
<pre class="prettyprint">buff.append_float(12.234, 4)    # Append number as a 32-bit IEEE 754 floating point number (4 bytes)

buff.append_float(12.234, 8)    # Append number as a 64-bit IEEE 754 floating point number (8 bytes)
</pre>
<p>Appending buffers</p>
<pre class="prettyprint">buff.append_buffer(other_buffer)    # Append other_buffer to buff
</pre>
<p>Appending strings</p>
<pre class="prettyprint">buff.append_str(str)                      # Append string as UTF-8 encoded bytes

buff.append_str(str, 'UTF-16')            # Append string as sequence of bytes in specified encodingt
</pre>
<h3 id="random-access-buffer-writes">Random access buffer writes</h3><br/>
<p>You can also write into the buffer at a specific index, by using the <code>set_XXX</code> methods. Set methods exist for other buffers, String, Float and FixNum. All the set methods take an index as the first argument - this represents the position in the buffer where to start writing the data.</p>
<p>When setting a FixNum you have to specify how many bytes you want to set this as in the buffer. Valid values are 1, 2, 4, 8.</p>
<p>When setting a Float you have to specify how many bytes you want to set this as in the buffer. Valid values are 4, 8.</p>
<p>The buffer will always expand as necessary to accomodate the data.</p>
<pre class="prettyprint">from core.buffer import Buffer

buff = Buffer.create

buff.set_fixnum(0, 4, 123123) # Set number as 4 bytes written at index 0 
buff.set_float(1000, 8, 414.123123123) # Set float as 8 bytes at index 1000
</pre>
<p>To set FixNums:</p>
<pre class="prettyprint">buff.set_fixnum(100, 123, 1)    # Set number as a single signed byte at position 100

buff.set_fixnum(100, 123, 2)    # Set number as a signed two byte integer at position 100

buff.set_fixnum(100, 123, 4)    # Set number as a signed four byte integer at position 100

buff.set_fixnum(100, 123, 8)    # Set number as a signed eight byte integer at position 100
</pre>
<p>To set Floats:</p>
<pre class="prettyprint">buff.set_float(100, 1.234, 4)   # Set the number as a 32-bit IEEE 754 floating point number (4 bytes) at pos 100

buff.set_float(100, 1.234, 8)   # Set the number as a 64-bit IEEE 754 floating point number (4 bytes) at pos 100
</pre>
<p>To set a buffer</p>
<pre class="prettyprint">buff.set_buffer(100, other_buffer)
</pre>
<p>To set a string</p>
<pre class="prettyprint">buff.set_string(100, str) # Set the string using UTF-8 encoding

buff.set_string(100, str, 'UTF-16') # Set the string using the specified encoding
</pre>
<h2 id="reading-from-a-buffer">Reading from a Buffer</h2><br/>
<p>Data is read from a buffer using the <code>get_XXX</code> methods. Get methods exist for byte, FixNum and Float. The first argument to these methods is an index in the buffer from where to get the data.</p>
<p>When reading FixNum values the data in the buffer is interpreted as a signed integer value.</p>
<pre class="prettyprint">num = buff.get_byte(100)                 # Get a byte from pos 100 in buffer

num = buff.get_fixnum(100, 1)            # Same as get_byte

num = buff.get_fixnum(100, 2)            # Get two bytes as signed integer from pos 100

num = buff.get_fixnum(100, 4)            # Get four bytes as signed integer from pos 100

num = buff.get_fixnum(100, 8)            # Get eight bytes as signed integer from pos 100
</pre>
<p>Floats:</p>
<pre class="prettyprint">num = buff.get_float(100, 4)             # Get four bytes as a 32-bit IEEE 754 floating point number from pos 100

num = buff.get_float(100, 8)             # Get eight bytes as a 32-bit IEEE 754 floating point number from pos 100
</pre>
<p>Strings:</p>
<pre class="prettyprint">str = buff.get_string(100, 110)           # Get 10 bytes from pos 100 interpreted as UTF-8 string

str = buff.get_string(100, 110, 'UTF-16') # Get 10 bytes from pos 100 interpreted in specified encoding
</pre>
<p>Buffers:</p>
<pre class="prettyprint">other_buff = buff.get_buffer(100, 110)    # Get 10 bytes as a new buffer starting at position 100
</pre>
<h2 id="other-buffer-methods">Other buffer methods:</h2><br/>
<ul>
<li><code>length</code>: To obtain the length of the buffer. The length of a buffer is the index of the byte in the buffer with the largest index + 1.</li>
<li><code>copy</code>: Copy the entire buffer</li>
</ul>
<p>See the Yardoc for more detailed method level documentation.    </p>
<h1 id="delayed-and-periodic-tasks">Delayed and Periodic Tasks</h1><br/>
<p>It's very common in vert.x to want to perform an action after a delay, or periodically.</p>
<p>In standard verticles you can't just make the thread sleep to introduce a delay, as that will block the event loop thread.</p>
<p>Instead you use vert.x timers. Timers can be <em>one-shot</em> or <em>periodic</em>. We'll discuss both</p>
<h2 id="one-shot-timers">One-shot Timers</h2><br/>
<p>A one shot timer calls an event handler after a certain delay, expressed in milliseconds.</p>
<p>To set a timer to fire once you use the <code>vertx.set_timer</code> function passing in the delay and specifying a handler block which will be called when after the delay:</p>
<pre class="prettyprint">import vertx

def handler(tid):
    print 'And one second later this is printed'

tid = vertx.set_timer(1000, handler)

print 'First this is printed'
</pre>
<h2 id="periodic-timers">Periodic Timers</h2><br/>
<p>You can also set a timer to fire periodically by using the <code>set_periodic</code> function. There will be an initial delay equal to the period. The return value of <code>set_periodic</code> is a unique timer id (number). This can be later used if the timer needs to be cancelled. The argument passed into the timer event handler is also the unique timer id:</p>
<pre class="prettyprint">import vertx

def handler(tid):
    print 'And every second this is printed'

tid = vertx.set_periodic(1000, handler)

print 'First this is printed'
</pre>
<h2 id="cancelling-timers">Cancelling timers</h2><br/>
<p>To cancel a timer, call the <code>cancel_timer</code> function specifying the timer id. For example:</p>
<pre class="prettyprint">import vertx

def handler(tid):
    # This will never be called
    pass

tid = vertx.set_periodic(1000, handler)

# And immediately cancel it

vertx.cancel_timer(tid)
</pre>
<p>Or you can cancel it from inside the event handler. The following example cancels the timer after it has fired 10 times.</p>
<pre class="prettyprint">import vertx

class Counter:
    pass
Counter.count = 0

def handler(tid):
    print "In event handler : %d" % Counter.count
    Counter.count += 1
    if Counter.count == 10:
        vertx.cancel_timer(tid)
</pre>
<p>vertx.set_periodic(500, handler)</p>
<h1 id="writing-tcp-servers-and-clients">Writing TCP Servers and Clients</h1><br/>
<p>Creating TCP servers and clients is incredibly easy with vert.x.</p>
<h2 id="net-server">Net Server</h2><br/>
<h3 id="creating-a-net-server">Creating a Net Server</h3><br/>
<p>To create a TCP server we simply create an instance of core.net.NetServer</p>
<pre class="prettyprint">import vertx
server = vertx.create_net_server()
</pre>
<h3 id="start-the-server-listening">Start the Server Listening</h3><br/>
<p>To tell that server to listen for connections we do:</p>
<pre class="prettyprint">import vertx
server = vertx.create_net_server()

server.listen(1234, 'myhost')
</pre>
<p>The first parameter to <code>listen</code> is the port. The second parameter is the hostname or ip address. If it is ommitted it will default to <code>0.0.0.0</code> which means it will listen at all available interfaces.</p>
<h3 id="getting-notified-of-incoming-connections">Getting Notified of Incoming Connections</h3><br/>
<p>Just having a TCP server listening creates a working server that you can connect to (try it with telnet!), however it's not very useful since it doesn't do anything with the connections.</p>
<p>To be notified when a connection occurs we need to call the <code>connect_handler</code> function of the server, specifying a block which represents the handler. The handler will be called when a connection is made:</p>
<pre class="prettyprint">import vertx

server = vertx.create_net_server()

@server.connect_handler
def connect_handler():
    print 'A client has connected!'

server.listen(1234, 'localhost')
</pre>
<p>That's a bit more interesting. Now it displays 'A client has connected!' every time a client connects.</p>
<p>The return value of the <code>connect_handler</code> method is the server itself, so multiple invocations can be chained together. That means we can rewrite the above as:</p>
<pre class="prettyprint">import vertx

server = vertx.create_net_server()

@server.connect_handler
def connect_handler()
    print 'A client has connected!'
server.listen(1234, 'localhost')
</pre>
<p>This is a common pattern throughout the vert.x API.</p>
<h3 id="closing-a-net-server">Closing a Net Server</h3><br/>
<p>To close a net server just call the <code>close</code> method.</p>
<pre class="prettyprint">server.close()
</pre>
<p>The close is actually asynchronous and might not complete until some time after the <code>close</code> method has returned. If you want to be notified when the actual close has completed then you can specify a block to the <code>close</code> function.</p>
<p>This block will then be called when the close has fully completed.</p>
<pre class="prettyprint">def close_handler():
    print 'The server is now fully closed.'

server.close(close_handler)
</pre>
<p>In most cases you don't need to close a net server explicitly since vert.x will close them for you when the verticle stops.    </p>
<h3 id="netserver-properties">NetServer Properties</h3><br/>
<p>NetServer has a set of attributes you can set which affect its behaviour. Firstly there are bunch of attributes used to tweak the TCP parameters, in most cases you won't need to set these:</p>
<ul>
<li>
<p><code>tcp_no_delay</code> If this attribute is true then <a href="http://en.wikipedia.org/wiki/Nagle's_algorithm">Nagle's Algorithm</a> is disabled. If false then it is enabled.</p>
</li>
<li>
<p><code>send_buffer_size</code> Sets the TCP send buffer size in bytes.</p>
</li>
<li>
<p><code>receive_buffer_size</code> Sets the TCP receive buffer size in bytes.</p>
</li>
<li>
<p><code>tcp_keep_alive</code> if this attribute is true then <a href="http://en.wikipedia.org/wiki/Keepalive#TCP_keepalive">TCP keep alive</a> is enabled, if false it is disabled.</p>
</li>
<li>
<p><code>reuse_address</code> if this attribute is true then addresses in TIME_WAIT state can be reused after they have been closed.</p>
</li>
<li>
<p><code>so_linger</code></p>
</li>
<li>
<p><code>traffic_class</code></p>
</li>
</ul>
<p>NetServer has a further set of properties which are used to configure SSL. We'll discuss those later on.</p>
<h3 id="handling-data">Handling Data</h3><br/>
<p>So far we have seen how to create a <code>NetServer</code>, and accept incoming connections, but not how to do anything interesting with the connections. Let's remedy that now.</p>
<p>When a connection is made, the connect handler is called passing in an instance of <code>NetSocket</code>. This is a socket-like interface to the actual connection, and allows you to read and write data as well as do various other things like close the socket.</p>
<h4 id="reading-data-from-the-socket">Reading Data from the Socket</h4><br/>
<p>To read data from the socket you need to set the <code>data_handler</code> on the socket. This handler will be called with a <code>Buffer</code> every time data is received on the socket. You could try the following code and telnet to it to send some data:</p>
<pre class="prettyprint">import vertx

server = vertx.create_net_server()

@server.connect_handler
def connect_handler(sock):
    def data_handler(buffer):
        print "I received %s bytes of data"% buffer.length
    sock.data_handler(data_handler)
server.listen(1234, 'localhost')
</pre>
<h4 id="writing-data-to-a-socket">Writing Data to a Socket</h4><br/>
<p>To write data to a socket, you invoke one of the write methods. </p>
<p>With a single buffer:
    from core.buffer import Buffer</p>
<pre class="prettyprint">myBuffer = Buffer.create(...)
sock.write_buffer(myBuffer)
</pre>
<p>A string. In this case the string will encoded using UTF-8 and the result written to the wire.</p>
<pre class="prettyprint">sock.write_str('hello')
</pre>
<p>A string and an encoding. In this case the string will encoded using the specified encoding and the result written to the wire.</p>
<pre class="prettyprint">sock.write_str('hello', 'UTF-16')
</pre>
<p>The write methods are asynchronous and always returns immediately after the write has been queued.</p>
<p>The actual write might occur some time later. If you want to be informed when the actual write has happened you can specify a block to the method:</p>
<p>This block will then be invoked when the write has completed:</p>
<pre class="prettyprint">def done_handler():
    print 'It has actually been written'
sock.write_str('hello', done_handler)
</pre>
<p>Let's put it all together.</p>
<p>Here's an example of a simple TCP echo server which simply writes back (echoes) everything that it receives on the socket:</p>
<pre class="prettyprint">import vertx

server = vertx.create_net_server()

@server.connect_handler
def connect_handler(sock):
    def data_handler(buffer):
        sock.write(buffer)
    sock.data_handler(data_handler)

server.listen(1234, 'localhost')
</pre>
<h3 id="closing-a-socket">Closing a socket</h3><br/>
<p>You can close a socket by invoking the <code>close</code> method. This will close the underlying TCP connection.</p>
<h3 id="closed-handler">Closed Handler</h3><br/>
<p>If you want to be notified when a socket is closed, you can set the `closed_handler':</p>
<pre class="prettyprint">import vertx

server = vertx.create_net_server()

@server.connect_handler
def connect_handler(sock):
    def closed_handler():
        print 'The socket is now closed'
    sock.closed_handler(closed_handler)
</pre>
<p>The closed handler will be called irrespective of whether the close was initiated by the client or server.</p>
<h3 id="exception-handler">Exception handler</h3><br/>
<p>You can set an exception handler on the socket that will be called if an exception occurs:</p>
<pre class="prettyprint">import vertx
server = vertx.create_net_server()

@server.connect_handler
def connect_handler(sock):
    @sock.exception_handler
    def exception_handler(e):
        print 'Oops. Something went wrong'
</pre>
<h3 id="read-and-write-streams">Read and Write Streams</h3><br/>
<p>NetSocket also can at as a <code>ReadStream</code> and a <code>WriteStream</code>. This allows flow control to occur on the connection and the connection data to be pumped to and from other object such as HTTP requests and responses, WebSockets and asynchronous files.</p>
<p>This will be discussed in depth in the chapter on streams and pumps.</p>
<h2 id="scaling-tcp-servers">Scaling TCP Servers</h2><br/>
<p>A verticle instance is strictly single threaded.</p>
<p>If you create a simple TCP server and deploy a single instance of it then all the handlers for that server are always executed on the same event loop (thread).</p>
<p>This means that if you are running on a server with a lot of cores, and you only have this one instance deployed then you will have at most one core utilised on your server! That's not very good, right?</p>
<p>To remedy this you can simply deploy more instances of the verticle in the server, e.g.</p>
<pre class="prettyprint">vertx run echo_server.py -instances 20
</pre>
<p>The above would run 20 instances of echo_server.rb to a locally running vert.x instance.</p>
<p>Once you do this you will find the echo server works functionally identically to before, but, <em>as if by magic</em>, all your cores on your server can be utilised and more work can be handled.</p>
<p>At this point you might be asking yourself <em>'Hold on, how can you have more than one server listening on the same host and port? Surely you will get port conflicts as soon as you try and deploy more than one instance?'</em></p>
<p><em>Vert.x does a little magic here</em>.</p>
<p>When you deploy another server on the same host and port as an existing server it doesn't actually try and create a new server listening on the same host/port.</p>
<p>Instead it internally maintains just a single server, and, as incoming connections arrive it distributes them in a round-robin fashion to any of the connect handlers set by the verticles.</p>
<p>Consequently vert.x TCP servers can scale over available cores while each vert.x verticle instance remains strictly single threaded, and you don't have to do any special tricks like writing load-balancers in order to scale your server on your multi-core machine.</p>
<h2 id="netclient">NetClient</h2><br/>
<p>A NetClient is used to make TCP connections to servers.</p>
<h3 id="creating-a-net-client">Creating a Net Client</h3><br/>
<p>To create a TCP client we simply create an instance of <code>core.net.NetClient</code>.</p>
<pre class="prettyprint">import vertx

client = vertx.create_net_client()
</pre>
<h3 id="making-a-connection">Making a Connection</h3><br/>
<p>To actually connect to a server you invoke the <code>connect</code> method</p>
<pre class="prettyprint">import vertx

client = vertx.create_net_client()

def connect_handler(sock):
    print 'We have connected'

client.connect(1234, 'localhost', connect_handler)
</pre>
<p>The connect method takes the port number as the first parameter, followed by the hostname or ip address of the server. It takes a block as the connect handler. This handler will be called when the connection actually occurs.</p>
<p>The argument passed into the connect handler is an instance of <code>NetSocket</code>, exactly the same as what is passed into the server side connect handler. Once given the <code>NetSocket</code> you can read and write data from the socket in exactly the same way as you do on the server side.</p>
<p>You can also close it, set the closed handler, set the exception handler and use it as a <code>ReadStream</code> or <code>WriteStream</code> exactly the same as the server side <code>NetSocket</code>.</p>
<h3 id="catching-exceptions-on-the-net-client">Catching exceptions on the Net Client</h3><br/>
<p>You can set an exception handler on the <code>NetClient</code>. This will catch any exceptions that occur during connection.</p>
<pre class="prettyprint">import vertx

client = vertx.create_net_client()

@client.exception_handler
def exception_handler(ex):
    print 'Cannot connect since the host does not exist!'

def connect_handler(sock):
    print "this won't get called"

client.connect(4242, 'host-that-doesnt-exist', connect_handler)
</pre>
<h3 id="configuring-reconnection">Configuring Reconnection</h3><br/>
<p>A NetClient can be configured to automatically retry connecting or reconnecting to the server in the event that it cannot connect or has lost its connection. This is done by invoking setting the attributes <code>reconnect_attempts</code> and <code>reconnect_interval</code>:</p>
<pre class="prettyprint">import vertx

client = vertx.create_net_client()

client.reconnect_attempts = 1000

client.reconnect_interval = 500
</pre>
<p><code>reconnect_attempts</code> determines how many times the client will try to connect to the server before giving up. A value of <code>-1</code> represents an infinite number of times. The default value is <code>0</code>. I.e. no reconnection is attempted.</p>
<p><code>reconnect_interval</code> determines how long, in milliseconds, the client will wait between reconnect attempts. The default value is <code>1000</code>.</p>
<p>If an exception handler is set on the client, and reconnect attempts is not equal to <code>0</code>. Then the exception handler will not be called until the client gives up reconnecting.</p>
<h3 id="netclient-properties">NetClient Properties</h3><br/>
<p>Just like <code>NetServer</code>, <code>NetClient</code> also has a set of TCP properties you can set which affect its behaviour. They have the same meaning as those on <code>NetServer</code>.</p>
<p><code>NetClient</code> also has a further set of properties which are used to configure SSL. We'll discuss those later on.</p>
<h2 id="ssl-servers">SSL Servers</h2><br/>
<p>Net servers can also be configured to work with <a href="http://en.wikipedia.org/wiki/Transport_Layer_Security">Transport Layer Security</a> (previously known as SSL).</p>
<p>When a <code>NetServer</code> is working as an SSL Server the API of the <code>NetServer</code> and <code>NetSocket</code> is identical compared to when it working with standard sockets. Getting the server to use SSL is just a matter of configuring the <code>NetServer</code> before <code>listen</code> is called.</p>
<p>To enabled SSL set the attribute <code>ssl</code> to <code>True</code> on the <code>NetServer</code>.</p>
<p>The server must also be configured with a <em>key store</em> and an optional <em>trust store</em>.</p>
<p>These are both <em>Java keystores</em> which can be managed using the <a href="http://docs.oracle.com/javase/6/docs/technotes/tools/solaris/keytool.html">keytool</a> utility which ships with the JDK.</p>
<p>The keytool command allows you to create keystores, and import and export certificates from them.</p>
<p>The key store should contain the server certificate. This is mandatory - the client will not be able to connect to the server over SSL if the server does not have a certificate.</p>
<p>The key store is configured on the server using the attributes <code>key_store_path</code> and <code>key_store_password</code>.</p>
<p>The trust store is optional and contains the certificates of any clients it should trust. This is only used if client authentication is required.</p>
<p>To configure a server to use server certificates only:</p>
<pre class="prettyprint">import vertx
server = vertx.create_net_server()
server.ssl = True
server.key_store_path = '/path/to/your/keystore/server-keystore.jks'
server.key_store_password = 'password'
</pre>
<p>Making sure that <code>server-keystore.jks</code> contains the server certificate.</p>
<p>To configure a server to also require client certificates:</p>
<pre class="prettyprint">import vertx
server = vertx.create_net_server()
server.ssl = True
server.key_store_path = '/path/to/your/keystore/server-keystore.jks'
server.key_store_password = 'password'
server.client_auth_required = True
server.trust_store_path = '/path/to/your/truststore/server-truststore.jks'
server.trust_store_password = 'password'
</pre>
<p>Making sure that <code>server-truststore.jks</code> contains the certificates of any clients who the server trusts.</p>
<p>If the attribute <code>client_auth_required</code> is set to <code>true</code> and the client cannot provide a certificate, or it provides a certificate that the server does not trust then the connection attempt will not succeed.</p>
<h2 id="ssl-clients">SSL Clients</h2><br/>
<p>Net Clients can also be easily configured to use SSL. They have the exact same API when using SSL as when using standard sockets.</p>
<p>To enable SSL on a <code>NetClient</code> the attribute <code>ssl</code> must be set to <code>true</code>.</p>
<p>If the attribute <code>trust_all</code> has been set to <code>true</code>, then the client will trust all server certificates. The connection will still be encrypted but this mode is vulnerable to 'man in the middle' attacks. I.e. you can't be sure who you are connecting to. Use this with caution. Default value is <code>false</code>.</p>
<p>If <code>trust_all</code> is set to <code>false</code>, then a client trust store must be configured and should contain the certificates of the servers that the client trusts.</p>
<p>The default value of <code>trust_all</code> is <code>false</code>.</p>
<p>The client trust store is just a standard Java key store, the same as the key stores on the server side. The client trust store location is set by setting the attribute <code>trust_store_path</code> on the <code>NetClient</code>. If a server presents a certificate during connection which is not in the client trust store, the connection attempt will not succeed.</p>
<p>If the server requires client authentication then the client must present its own certificate to the server when connecting. This certificate should reside in the client key store. Again it's just a regular Java key store. The client keystore location is set with the attribute <code>key_store_path</code> on the <code>NetClient</code>.</p>
<p>To configure a client to trust all server certificates (dangerous):</p>
<pre class="prettyprint">import vertx
client = vertx.create_net_client()
client.ssl = True
client.trust_all = True
</pre>
<p>To configure a client to only trust those certificates it has in its trust store:</p>
<pre class="prettyprint">import vertx
client = vertx.create_net_client()
client.ssl = True
client.trust_store_path = '/path/to/your/client/truststore/client-truststore.jks'
client.trust_store_password = 'password'
</pre>
<p>To configure a client to only trust those certificates it has in its trust store, and also to supply a client certificate:</p>
<pre class="prettyprint">import vertx
client = vertx.create_net_client()
client.ssl = True
client.trust_store_path = '/path/to/your/client/truststore/client-truststore.jks'
client.trust_store_password = 'password'
client.key_store_path = '/path/to/keystore/holding/client/cert/client-keystore.jks'
client.key_store_password = 'password'
</pre>
<h1 id="flow-control-streams-and-pumps">Flow Control - Streams and Pumps</h1><br/>
<p>There are several objects in vert.x that allow data to be read from and written to in the form of Buffers.</p>
<p>All operations in the vert.x API are non blocking; calls to write data return immediately and writes are internally queued.</p>
<p>It's not hard to see that if you write to an object faster than it can actually write the data to its underlying resource then the write queue could grow without bound - eventually resulting in exhausting available memory.</p>
<p>To solve this problem a simple flow control capability is provided by some objects in the vert.x API.</p>
<p>Any flow control aware object that can be written to is said to implement <code>ReadStream</code>, and any flow control object that can be read from is said to implement <code>WriteStream</code>.</p>
<p>Let's take an example where we want to read from a <code>ReadStream</code> and write the data to a <code>WriteStream</code>.</p>
<p>A very simple example would be reading from a <code>NetSocket</code> on a server and writing back to the same <code>NetSocket</code> - since <code>NetSocket</code> implements both <code>ReadStream</code> and <code>WriteStream</code>, but you can do this between any <code>ReadStream</code> and any <code>WriteStream</code>, including HTTP requests and response, async files, WebSockets, etc.</p>
<p>A naive way to do this would be to directly take the data that's been read and immediately write it to the NetSocket, for example:</p>
<pre class="prettyprint">import vertx
server = vertx.create_net_server()

@server.connect_handler
def connect_handler(sock):
    @sock.data_handler
    def data_handler(buffer):
        # Write the data straight back
        sock.write(buffer)

server.listen(1234, 'localhost')
</pre>
<p>There's a problem with the above example: If data is read from the socket faster than it can be written back to the socket, it will build up in the write queue of the AsyncFile, eventually running out of RAM. This might happen, for example if the client at the other end of the socket wasn't reading very fast, effectively putting back-pressure on the connection.</p>
<p>Since <code>NetSocket</code> implements <code>WriteStream</code>, we can check if the <code>WriteStream</code> is full before writing to it:</p>
<pre class="prettyprint">import vertx
server = vertx.create_net_server()

@server.connect_handler
def connect_handler(sock):
    @sock.data_handler
    def data_handler(buffer):
        if not sock.write_queue_full:
            sock.write(buffer)

server.listen(1234, 'localhost')
</pre>
<p>This example won't run out of RAM but we'll end up losing data if the write queue gets full. What we really want to do is pause the <code>NetSocket</code> when the <code>AsyncFile</code> write queue is full. Let's do that:</p>
<pre class="prettyprint">import vertx
server = vertx.create_net_server()

@server.connect_handler
def connect_handler(sock):
    @sock.data_handler
    def data_handler(buffer):
        if sock.write_queue_full:
            sock.pause()
        else:
          sock.write(buffer)

server.listen(1234, 'localhost')
</pre>
<p>We're almost there, but not quite. The <code>NetSocket</code> now gets paused when the file is full, but we also need to <em>unpause</em> it when the file write queue has processed its backlog:</p>
<pre class="prettyprint">import vertx
server = vertx.create_net_server()

@server.connect_handler
def connect_handler(sock):
    @sock.data_handler
    def data_handler(buffer):
        if sock.write_queue_full:
            sock.pause()
            @sock.drain_handler
            def drain_handler(): 
                sock.resume()
        else:
            sock.write(buffer)

server.listen(1234, 'localhost')
</pre>
<p>And there we have it. The <code>drain_handler</code> event handler will get called when the write queue is ready to accept more data, this resumes the <code>NetSocket</code> which allows it to read more data.</p>
<p>It's very common to want to do this when writing vert.x applications, so we provide a helper class called <code>Pump</code> which does all this hard work for you. You just feed it the <code>ReadStream</code> and the <code>WriteStream</code> and it tell it to start:</p>
<pre class="prettyprint">import vertx
from core.streams import Pump
server = vertx.create_net_server()

@server.connect_handler
def connect_handler(sock):

    pump = Pump(sock, sock)
    pump.start()

server.listen(1234, 'localhost')
</pre>
<p>Which does exactly the same thing as the more verbose example.</p>
<p>Let's look at the methods on <code>ReadStream</code> and <code>WriteStream</code> in more detail:</p>
<h2 id="readstream">ReadStream</h2><br/>
<p><code>ReadStream</code> is implemented by <code>AsyncFile</code>, <code>HttpClientResponse</code>, <code>HttpServerRequest</code>, <code>WebSocket</code>, <code>NetSocket</code> and <code>SockJSSocket</code>.</p>
<p>Functions:</p>
<ul>
<li><code>data_handler</code>: set a handler which will receive data from the <code>ReadStream</code>. As data arrives the handler will be passed a Buffer.</li>
<li><code>pause</code>: pause the handler. When paused no data will be received in the <code>data_handler</code>.</li>
<li><code>resume</code>: resume the handler. The handler will be called if any data arrives.</li>
<li><code>exception_handler</code>: Will be called if an exception occurs on the <code>ReadStream</code>.</li>
<li><code>end_handler</code>: Will be called when end of stream is reached. This might be when EOF is reached if the <code>ReadStream</code> represents a file, or when end of request is reached if it's an HTTP request, or when the connection is closed if it's a TCP socket.</li>
</ul>
<h2 id="writestream">WriteStream</h2><br/>
<p><code>WriteStream</code> is implemented by <code>AsyncFile</code>, <code>HttpClientRequest</code>, <code>HttpServerResponse</code>, <code>WebSocket</code>, <code>NetSocket</code> and <code>SockJSSocket</code></p>
<p>Functions:</p>
<ul>
<li><code>write_buffer</code>: write a Buffer to the <code>WriteStream</code>. This method will never block. Writes are queued internally and asynchronously written to the underlying resource.</li>
<li><code>write_queue_max_size=</code>: set the number of bytes at which the write queue is considered <em>full</em>, and the function <code>write_queue_full</code> returns <code>True</code>. Note that, even if the write queue is considered full, if <code>writeBuffer</code> is called the data will still be accepted and queued.</li>
<li><code>write_queue_full</code>: returns <code>True</code> if the write queue is considered full.</li>
<li><code>exception_handler</code>: Will be called if an exception occurs on the <code>WriteStream</code>.</li>
<li><code>drain_handler</code>: The handler will be called if the <code>WriteStream</code> is considered no longer full.</li>
</ul>
<h2 id="pump">Pump</h2><br/>
<p>Instances of <code>Pump</code> have the following methods:</p>
<ul>
<li><code>start</code>. Start the pump.</li>
<li><code>stop</code>. Stops the pump. When the pump starts it is in stopped mode.</li>
<li><code>write_queue_max_size=</code>. This has the same meaning as <code>write_queue_max_size=</code> on the <code>WriteStream</code>.</li>
<li><code>bytes_pumped</code>. Returns total number of bytes pumped.</li>
</ul>
<p>A pump can be started and stopped multiple times.</p>
<h1 id="writing-http-servers-and-clients">Writing HTTP Servers and Clients</h1><br/>
<h2 id="writing-http-servers">Writing HTTP servers</h2><br/>
<p>Vert.x allows you to easily write full featured, highly performant and scalable HTTP servers.</p>
<h3 id="creating-an-http-server">Creating an HTTP Server</h3><br/>
<p>To create an HTTP server you simply create an instance of <code>core.http.HttpServer</code>.</p>
<pre class="prettyprint">server = vertx.create_net_server()
</pre>
<h3 id="start-the-server-listening_1">Start the Server Listening</h3><br/>
<p>To tell that server to listen for incoming requests you use the <code>listen</code> method:</p>
<pre class="prettyprint">server = vertx.create_net_server()

server.listen(8080, 'myhost')
</pre>
<p>The first parameter to <code>listen</code> is the port. The second parameter is the hostname or ip address. If the hostname is omitted it will default to <code>0.0.0.0</code> which means it will listen at all available interfaces.</p>
<h3 id="getting-notified-of-incoming-requests">Getting Notified of Incoming Requests</h3><br/>
<p>To be notified when a request arrives you need to set a request handler. This is done by calling the <code>request_handler</code> method of the server, passing in the handler:</p>
<pre class="prettyprint">import vertx

server = vertx.create_net_server()
@server.request_handler
def request_handler(request):
    print 'An HTTP request has been received'

server.listen(8080, 'localhost')
</pre>
<p>This displays 'An HTTP request has been received!' every time an HTTP request arrives on the server. You can try it by running the verticle and pointing your browser at <code>http://localhost:8080</code>.</p>
<p>Similarly to <code>NetServer</code>, the return value of the <code>request_handler</code> function is the server itself, so multiple invocations can be chained together. That means we can rewrite the above with:</p>
<pre class="prettyprint">import vertx

server = vertx.create_net_server()
@server.request_handler
def request_handler(request):
    print 'An HTTP request has been received'
server.listen(8080, 'localhost')
</pre>
<h3 id="handling-http-requests">Handling HTTP Requests</h3><br/>
<p>So far we have seen how to create an <code>HttpServer</code> and be notified of requests. Lets take a look at how to handle the requests and do something useful with them.</p>
<p>When a request arrives, the request handler is called passing in an instance of <code>HttpServerRequest</code>. This object represents the server side HTTP request.</p>
<p>The handler is called when the headers of the request have been fully read. If the request contains a body, that body may arrive at the server some time after the request handler has been called.</p>
<p>It contains functions to get the URI, path, request headers and request parameters. It also contains a <code>response</code> property which is a reference to an object that represents the server side HTTP response for the object.</p>
<h4 id="request-method">Request Method</h4><br/>
<p>The request object has a property <code>method</code> which is a string representing what HTTP method was requested. Possible values for <code>method</code> are: <code>GET</code>, <code>PUT</code>, <code>POST</code>, <code>DELETE</code>, <code>HEAD</code>, <code>OPTIONS</code>, <code>CONNECT</code>, <code>TRACE</code>, <code>PATCH</code>.</p>
<h4 id="request-uri">Request URI</h4><br/>
<p>The request object has a property <code>uri</code> which contains the full URI (Uniform Resource Locator) of the request. For example, if the request URI was:</p>
<pre class="prettyprint">/a/b/c/page.html?param1=abc&amp;param2=xyz
</pre>
<p>Then <code>request.uri</code> would contain the string <code>/a/b/c/page.html?param1=abc&amp;param2=xyz</code>.</p>
<p>Request URIs can be relative or absolute (with a domain) depending on what the client sent. In many cases they will be relative.</p>
<p>The request uri contains the value as defined in <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec5.html">Section 5.1.2 of the HTTP specification - Request-URI</a></p>
<h4 id="request-path">Request Path</h4><br/>
<p>The request object has a property <code>path</code> which contains the path of the request. For example, if the request URI was:</p>
<pre class="prettyprint">/a/b/c/page.html?param1=abc&amp;param2=xyz
</pre>
<p>Then <code>request.path</code> would contain the string <code>/a/b/c/page.html</code></p>
<h4 id="request-query">Request Query</h4><br/>
<p>The request object has a property <code>query</code> which contains the query of the request. For example, if the request URI was:</p>
<pre class="prettyprint">/a/b/c/page.html?param1=abc&amp;param2=xyz
</pre>
<p>Then <code>request.query</code> would contain the string <code>param1=abc&amp;param2=xyz</code></p>
<h4 id="request-headers">Request Headers</h4><br/>
<p>The request headers are available using the <code>headers</code> method on the request object. The return value of the method is a Ruby Hash.</p>
<p>Note that the header keys are always lower-cased before being returned to you.</p>
<p>Here's an example that echoes the headers to the output of the response. Run it and point your browser at <code>http://localhost:8080</code> to see the headers.</p>
<pre class="prettyprint">@server.request_handler
def request_handler(request):

  request.response.put_header('Content-Type', 'text/plain')

  str = "Headers are\n"
  @request.headers.each
  def each(key, value):
      str += "#{key}: #{value}\n"

  request.response.end(str)

server.listen(8080, 'localhost')
</pre>
<h4 id="request-params">Request params</h4><br/>
<p>Similarly to the headers, the request parameters are available using the <code>params</code> method on the request object. The return value of the function is just a Hash too.</p>
<p>Request parameters are sent on the request URI, after the path. For example if the URI was:</p>
<pre class="prettyprint">/page.html?param1=abc&amp;param2=xyz
</pre>
<p>Then the params hash would be the following JS object:</p>
<pre class="prettyprint">{ param1: 'abc', param2: 'xyz' }
</pre>
<h4 id="reading-data-from-the-request-body">Reading Data from the Request Body</h4><br/>
<p>Sometimes an HTTP request contains a request body that we want to read. As previously mentioned the request handler is called when only the headers of the request have arrived so the <code>HttpServerRequest</code> object does not contain the body. This is because the body may be very large and we don't want to create problems with exceeding available memory.</p>
<p>To receive the body, you set the <code>data_handler</code> on the request object. This will then get called every time a chunk of the request body arrives. Here's an example:</p>
<pre class="prettyprint">@server.request_handler
def request_handler(request):
    @request.data_handler
    def data_handler(buffer):
        print "I received %d bytes"% buffer.length
server.listen(8080, 'localhost')
</pre>
<p>The <code>data_handler</code> may be called more than once depending on the size of the body.</p>
<p>You'll notice this is very similar to how data from <code>NetSocket</code> is read.</p>
<p>The request object implements the <code>ReadStream</code> interface so you can pump the request body to a <code>WriteStream</code>. See the chapter on streams and pumps for a detailed explanation.</p>
<p>In many cases, you know the body is not large and you just want to receive it in one go. To do this you could do something like the following:</p>
<pre class="prettyprint">import vertx
from core.buffer import Buffer

server = vertx.create_http_server()

@server.request_handler
def request_handler(request):

  # Create a buffer to hold the body
  body = Buffer.create(0)

  @request.data_handler
  def data_handler(buffer)
      # Append the chunk to the buffer
      body.append_buffer(buffer)

  @request.end_handler
  def end_handler():
      # The entire body has now been received
      print "The total body received was %d bytes"%body.length

server.listen(8080, 'localhost')
</pre>
<p>Like any <code>ReadStream</code> the end handler is invoked when the end of stream is reached - in this case at the end of the request.</p>
<p>If the HTTP request is using HTTP chunking, then each HTTP chunk of the request body will correspond to a single call of the data handler.</p>
<p>It's a very common use case to want to read the entire body before processing it, so vert.x allows a <code>body_handler</code> to be set on the request object.</p>
<p>The body handler is called only once when the <em>entire</em> request body has been read.</p>
<p><em>Beware of doing this with very large requests since the entire request body will be stored in memory.</em></p>
<p>Here's an example using <code>body_handler</code>:</p>
<pre class="prettyprint">import vertx

server = vertx.create_http_server()

@server.request_handler
def request_handler(request):
    @request.body_handler 
    def body_handler(body):
        print "The total body received was %d bytes"% body.length

server.listen(8080, 'localhost')
</pre>
<p>Simples, innit?</p>
<h3 id="http-server-responses">HTTP Server Responses</h3><br/>
<p>As previously mentioned, the HTTP request object contains a property <code>response</code>. This is the HTTP response for the request. You use it to write the response back to the client.</p>
<h3 id="setting-status-code-and-message">Setting Status Code and Message</h3><br/>
<p>To set the HTTP status code for the response use the <code>status_code</code> property. You can also use the <code>status_message</code> property to set the status message. If you do not set the status message a default message will be used.</p>
<pre class="prettyprint">import vertx

server = vertx.create_http_server()

@server.request_handler
def request_handler(request):

  request.response.status_code = 404
  request.response.status_message = "Too many gerbils"
  request.response.end()

server.listen(8080, 'localhost')
</pre>
<p>The default value for <code>status_code</code> is <code>200</code>.    </p>
<h4 id="writing-http-responses">Writing HTTP responses</h4><br/>
<p>To write data to an HTTP response, you invoke the <code>write_buffer</code> or <code>write_str</code> methods. These methods can be invoked multiple times before the response is ended.</p>
<p>With a single buffer:</p>
<pre class="prettyprint">myBuffer = ...
request.response.write_buffer(myBuffer)
</pre>
<p>A string. In this case the string will encoded using UTF-8 and the result written to the wire.</p>
<pre class="prettyprint">request.response.write_str('hello')
</pre>
<p>A string and an encoding. In this case the string will encoded using the specified encoding and the result written to the wire.</p>
<pre class="prettyprint">request.response.write_str('hello', 'UTF-16')
</pre>
<p>The write methods are asynchronous and always returns immediately after the write has been queued.</p>
<p>The actual write might complete some time later. If you want to be informed when the actual write has completed you can specify a block when calling the method. The block will then be invoked when the write has completed:</p>
<pre class="prettyprint">def done(): print 'It has actually been written' 
request.response.write_str('hello', done)
</pre>
<p>If you are just writing a single string or Buffer to the HTTP response you can write it and end the response in a single call to the <code>end</code> function.</p>
<p>The first call to write results in the response header being being written to the response.</p>
<p>Consequently, if you are not using HTTP chunking then you must set the <code>Content-Length</code> header before writing to the response, since it will be too late otherwise. If you are using HTTP chunking you do not have to worry.</p>
<h4 id="ending-http-responses">Ending HTTP responses</h4><br/>
<p>Once you have finished with the HTTP response you must call the <code>end</code> method on it.</p>
<p>This method can be invoked in several ways:</p>
<p>With no arguments, the response is simply ended.</p>
<pre class="prettyprint">request.response.end()
</pre>
<p>The function can also be called with a string or Buffer in the same way write is called. In this case it's just the same as calling write with a string or Buffer followed by calling <code>end</code> with no arguments. For example:</p>
<pre class="prettyprint">request.response.end('That's all folks')
</pre>
<h4 id="closing-the-underlying-connection">Closing the underlying connection</h4><br/>
<p>You can close the underlying TCP connection of the request by calling the <code>close</code> method.</p>
<pre class="prettyprint">request.response.close()
</pre>
<h4 id="response-headers">Response headers</h4><br/>
<p>HTTP response headers can be added to the response by adding them to the Hash returned from the <code>headers</code> method:</p>
<pre class="prettyprint">request.response.headers['Some-header'] = 'foo'
</pre>
<p>Also, individual HTTP response headers can be written using the <code>put_header</code> function, allowing a more fluent API. For example:</p>
<pre class="prettyprint">request.response.put_header('Some-Other-Header', 'wibble').
                 put_header('Blah', 'Eek')
</pre>
<p>Response headers must all be added before any parts of the response body are written.</p>
<h4 id="chunked-http-responses-and-trailers">Chunked HTTP Responses and Trailers</h4><br/>
<p>Vert.x supports <a href="http://en.wikipedia.org/wiki/Chunked_transfer_encoding">HTTP Chunked Transfer Encoding</a>. This allows the HTTP response body to be written in chunks, and is normally used when a large response body is being streamed to a client, whose size is not known in advance.</p>
<p>You put the HTTP response into chunked mode by setting the <code>chunked</code> property.</p>
<pre class="prettyprint">req.response.chunked = True
</pre>
<p>Default is non-chunked. When in chunked mode, each call to <code>response.write_buffer</code> or <code>response.write_str</code> will result in a new HTTP chunk being written out.</p>
<p>When in chunked mode you can also write HTTP response trailers to the response. These are actually written in the final chunk of the response.</p>
<p>Like headers, HTTP response trailers can be added to the response by adding them to the Hash returned from the <code>trailers</code> method:</p>
<pre class="prettyprint">request.response.trailers['Some-header'] = 'foo'
</pre>
<p>Also, individual HTTP response trailers can be written using the <code>put_trailer</code> method, allowing a more fluent API. For example:</p>
<pre class="prettyprint">request.response.put_trailer('Some-Other-Header', 'wibble').
                 put_trailer('Blah', 'Eek')
</pre>
<h3 id="serving-files-directly-from-disk">Serving files directly from disk</h3><br/>
<p>If you were writing a web server, one way to serve a file from disk would be to open it as an <code>AsyncFile</code> and pump it to the HTTP response. Or you could load it it one go using the file system API and write that to the HTTP response.</p>
<p>Alternatively, vert.x provides a method which allows you to send serve a file from disk to HTTP response in one operation. Where supported by the underlying operating system this may result in the OS directly transferring bytes from the file to the socket without being copied through userspace at all.</p>
<p>Using <code>send_file</code> is usually more efficient for large files, but may be slower than using <code>readFile</code> to manually read the file as a buffer and write it directly to the response.</p>
<p>To do this use the <code>send_file</code> function on the HTTP response. Here's a simple HTTP web server that serves static files from the local <code>web</code> directory:</p>
<pre class="prettyprint">import vertx

server = vertx.create_http_server()

@server.request_handler
def request_handler(request):
    file = ''
    if req.path == '/':
        file = 'index.html'
    elif '..' not in req.path:
        file = req.path
  req.response.send_file('web/' + file)
server.listen(8080, 'localhost')
</pre>
<p><em>Note: If you use <code>send_file</code> while using HTTPS it will copy through userspace, since if the kernel is copying data directly from disk to socket it doesn't give us an opportunity to apply any encryption.</em></p>
<p><strong>If you're going to write web servers using vert.x be careful that users cannot exploit the path to access files outside the directory from which you want to serve them.</strong></p>
<h3 id="pumping-responses">Pumping Responses</h3><br/>
<p>Since the HTTP Response implements <code>WriteStream</code> you can pump to it from any <code>ReadStream</code>, e.g. an <code>AsyncFile</code>, <code>NetSocket</code> or <code>HttpServerRequest</code>.</p>
<p>Here's an example which echoes HttpRequest headers and body back in the HttpResponse. It uses a pump for the body, so it will work even if the HTTP request body is much larger than can fit in memory at any one time:</p>
<pre class="prettyprint">import vertx
from core.streams import Pump

server = vertx.create_http_server()

@server.request_handler
def request_handler(request):

  req.response.put_headers(req.headers)

  p = Pump(req, req.response)
  p.start()

  @req.end_handler
  def end_handler(): req.response.end()

server.listen(8080, 'localhost')
</pre>
<h2 id="writing-http-clients">Writing HTTP Clients</h2><br/>
<h3 id="creating-an-http-client">Creating an HTTP Client</h3><br/>
<p>To create an HTTP client you simply create an instance of <code>core.http.HttpClient</code>:</p>
<pre class="prettyprint">client = vertx.create_http_client()
</pre>
<p>You set the port and hostname (or ip address) that the client will connect to using the <code>host</code> and <code>port</code> attributes:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.port = 8181
client.host = 'foo.com'
</pre>
<p>A single <code>HttpClient</code> always connects to the same host and port. If you want to connect to different servers, create more instances.</p>
<p>The default port is <code>80</code> and the default host is <code>localhost</code>. So if you don't explicitly set these values that's what the client will attempt to connect to.</p>
<h3 id="pooling-and-keep-alive">Pooling and Keep Alive</h3><br/>
<p>By default the <code>HttpClient</code> pools HTTP connections. As you make requests a connection is borrowed from the pool and returned when the HTTP response has ended.</p>
<p>If you do not want connections to be pooled you can set <code>keep_alive</code> to <code>False</code>:</p>
<pre class="prettyprint">client = client = vertx.create_http_client()
client.keep_alive = False
</pre>
<p>In this case a new connection will be created for each HTTP request and closed once the response has ended.</p>
<p>You can set the maximum number of connections that the client will pool as follows:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.max_pool_size = 10
</pre>
<p>The default value is <code>1</code>.</p>
<h3 id="closing-the-client">Closing the client</h3><br/>
<p>Vert.x will automatically close any clients when the verticle is stopped, but if you want to close it explicitly you can:</p>
<pre class="prettyprint">client.close()
</pre>
<h3 id="making-requests">Making Requests</h3><br/>
<p>To make a request using the client you invoke one the methods named after the HTTP method that you want to invoke.</p>
<p>For example, to make a <code>POST</code> request:</p>
<pre class="prettyprint">import vertx

client = vertx.create_http_client()
client.host = 'foo.com'

def response_handler(resp): print "got response %s"% resp.status_code
request = client.post('/some-path/', response_handler)

request.end()
</pre>
<p>To make a PUT request use the <code>put</code> method, to make a GET request use the <code>get</code> method, etc.</p>
<p>Legal request methods are: <code>get</code>, <code>put</code>, <code>post</code>, <code>delete</code>, <code>head</code>, <code>options</code>, <code>connect</code>, <code>trace</code> and <code>patch</code>.</p>
<p>The general modus operandi is you invoke the appropriate method passing in the request URI as the first parameter, the second parameter is an event handler which will get called when the corresponding response arrives. The response handler is passed the client response object as an argument.</p>
<p>The value specified in the request URI corresponds to the Request-URI as specified in <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec5.html">Section 5.1.2 of the HTTP specification</a>. In most cases it will be a relative URI.</p>
<p><em>Please note that the domain/port that the client connects to is determined by <code>setPort</code> and <code>setHost</code>, and is not parsed from the uri.</em></p>
<p>The return value from the appropriate request method is an <code>HttpClientRequest</code> object. You can use this to add headers to the request, and to write to the request body. The request object implements <code>WriteStream</code>.</p>
<p>Once you have finished with the request you must call the <code>end</code> method.</p>
<p>If you don't know the name of the request method in advance there is a general <code>request</code> method which takes the HTTP method as a parameter:</p>
<pre class="prettyprint">import vertx

client = vertx.create_http_client()
client.host = 'foo.com'
def response_handler(resp): print "got response %s"% resp.status_code
request = client.request('POST', '/some-path/', response_handler)

request.end()
</pre>
<p>There is also a method called <code>get_now</code> which does the same as <code>get</code>, but automatically ends the request. This is useful for simple GETs which don't have a request body:</p>
<pre class="prettyprint">import vertx

client = vertx.create_http_client()
client.host = 'foo.com'

def response_handler(resp): print "got response %s"% resp.status_code
client.get_now('/some-path/', response_handler)
</pre>
<p>With <code>get_now</code> there is no return value.</p>
<h4 id="writing-to-the-request-body">Writing to the request body</h4><br/>
<p>Writing to the client request body has a very similar API to writing to the server response body.</p>
<p>To write data to an <code>HttpClientRequest</code> object, you invoke the <code>write_buffer</code> or <code>write_str</code> methods. These methods can be called multiple times before the request has ended.</p>
<p>With a single buffer:</p>
<pre class="prettyprint">myBuffer = ...
request.write_buffer(myBuffer)
</pre>
<p>A string. In this case the string will encoded using UTF-8 and the result written to the wire.</p>
<pre class="prettyprint">request.write_str('hello')
</pre>
<p>A string and an encoding. In this case the string will encoded using the specified encoding and the result written to the wire.</p>
<pre class="prettyprint">request.write_str('hello', 'UTF-16')
</pre>
<p>The write functions are asynchronous and always return immediately after the write has been queued. The actual write might complete some time later.</p>
<p>If you want to be informed when the actual write has completed you specify a block to the method. This block will be invoked when the write has completed:</p>
<pre class="prettyprint">def handler(): print 'It has actually been written' 
request.response.write('hello', handler)
</pre>
<p>If you are just writing a single string or Buffer to the HTTP request you can write it and end the request in a single call to the <code>end</code> method.</p>
<p>The first call to <code>write</code> results in the request header being being written to the request.</p>
<p>Consequently, if you are not using HTTP chunking then you must set the <code>Content-Length</code> header before writing to the request, since it will be too late otherwise. If you are using HTTP chunking you do not have to worry.</p>
<h4 id="ending-http-requests">Ending HTTP requests</h4><br/>
<p>Once you have finished with the HTTP request you must call the <code>end</code> method on it.</p>
<p>This method can be invoked in several ways:</p>
<p>With no arguments, the request is simply ended.</p>
<pre class="prettyprint">request.end()
</pre>
<p>The method can also be called with a string or Buffer in the same way write is called. In this case it's just the same as calling write with a string or Buffer followed by calling <code>end</code> with no arguments.</p>
<h4 id="writing-request-headers">Writing Request Headers</h4><br/>
<p>To write headers to the request, add them to the Hash returned from the <code>headers</code> method:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.host = 'foo.com'

def response_handler(resp): print "got response %s"% resp.status_code

request = client.post('/some-path', response_handler)

request.headers['Some-Header'] = 'Some-Value'
request.end()
</pre>
<p>You can also use the <code>put_header</code> method to enable a more fluent API:    </p>
<pre class="prettyprint">client = vertx.create_http_client()
client.host = 'foo.com'

def response_handler(resp): print "got response %s"% resp.status_code

request = client.post('/some-path', response_handler). 
    put_header('Some-Header', 'Some-Value').
    put_header('Some-Other-Header', 'Some-Other-Value').
    end()
</pre>
<h4 id="http-chunked-requests">HTTP chunked requests</h4><br/>
<p>Vert.x supports <a href="http://en.wikipedia.org/wiki/Chunked_transfer_encoding">HTTP Chunked Transfer Encoding</a> for requests. This allows the HTTP request body to be written in chunks, and is normally used when a large request body is being streamed to the server, whose size is not known in advance.</p>
<p>You put the HTTP request into chunked mode by setting the attribute <code>chunked</code>.</p>
<pre class="prettyprint">request.chunked = True
</pre>
<p>Default is non-chunked. When in chunked mode, each call to <code>request.write_str</code> or <code>request.write_buffer</code> will result in a new HTTP chunk being written out.</p>
<h3 id="http-client-responses">HTTP Client Responses</h3><br/>
<p>Client responses are received as an argument to the response handler block that is specified when making a request.</p>
<p>The response object implements <code>ReadStream</code>, so it can be pumped to a <code>WriteStream</code> like any other <code>ReadStream</code>.</p>
<p>To query the status code of the response use the <code>status_code</code> property. The <code>status_message</code> property contains the status message. For example:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.host = 'foo.com'

def response_handler(resp): 
    print "server returned status code:  %s"% resp.status_code
    print "server returned status message: %s"% resp.status_message

client.get_now('/some-path', response_handler)
</pre>
<h4 id="reading-data-from-the-response-body">Reading Data from the Response Body</h4><br/>
<p>The API for reading a http client response body is very similar to the API for reading a http server request body.</p>
<p>Sometimes an HTTP response contains a request body that we want to read. Like an HTTP request, the client response handler is called when all the response headers have arrived, not when the entire response body has arrived.</p>
<p>To receive the response body, you set a <code>dataHandler</code> on the response object which gets called as parts of the HTTP response arrive. Here's an example:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.host = 'foo.com'

def response_handler(resp): 
    @resp.data_handler
    def data_handler(buffer):
        print "I received %s bytes"% buffer.length

client.get_now('/some-path', response_handler)
</pre>
<p>The response object implements the <code>ReadStream</code> interface so you can pump the response body to a <code>WriteStream</code>. See the chapter on streams and pump for a detailed explanation.</p>
<p>The <code>data_handler</code> can be called multiple times for a single HTTP response.</p>
<p>As with a server request, if you wanted to read the entire response body before doing something with it you could do something like the following:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.host = 'foo.com'

def response_handler(resp):

    # Create a buffer to hold the entire response body
    body = Buffer.create(0)

    @resp.data_handler
    def data_handler(buffer):
        # Add chunk to the buffer
        body.append_buffer(buffer)
    @resp.end_handler
    def end_handler():
        # The entire response body has been received
        print "The total body received was %s bytes"% body.length

client.get_now('/some-path', response_handler)
</pre>
<p>Like any <code>ReadStream</code> the end handler is invoked when the end of stream is reached - in this case at the end of the response.</p>
<p>If the HTTP response is using HTTP chunking, then each chunk of the response body will correspond to a single call to the <code>data_handler</code>.</p>
<p>It's a very common use case to want to read the entire body in one go, so vert.x allows a <code>body_handler</code> to be set on the response object.</p>
<p>The body handler is called only once when the <em>entire</em> response body has been read.</p>
<p><em>Beware of doing this with very large responses since the entire response body will be stored in memory.</em></p>
<p>Here's an example using <code>body_handler</code>:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.host = 'foo.com'

def response_handler(resp): 
    @resp.body_handler
    def body_handler(body):
        print "The total body received was %s bytes"% body.length
client.get_now('/some-path', response_handler)
</pre>
<h2 id="pumping-requests-and-responses">Pumping Requests and Responses</h2><br/>
<p>The HTTP client and server requests and responses all implement either <code>ReadStream</code> or <code>WriteStream</code>. This means you can pump between them and any other read and write streams.</p>
<h3 id="100-continue-handling">100-Continue Handling</h3><br/>
<p>According to the <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html">HTTP 1.1 specification</a> a client can set a header <code>Expect: 100-Continue</code> and send the request header before sending the rest of the request body.</p>
<p>The server can then respond with an interim response status <code>Status: 100 (Continue)</code> to signify the client is ok to send the rest of the body.</p>
<p>The idea here is it allows the server to authorise and accept/reject the request before large amounts of data is sent. Sending large amounts of data if the request might not be accepted is a waste of bandwidth and ties up the server in reading data that it will just discard.</p>
<p>Vert.x allows you to set a <code>continue_handler</code> on the client request object. This will be called if the server sends back a <code>Status: 100 (Continue)</code> response to signify it is ok to send the rest of the request.</p>
<p>This is used in conjunction with the <code>send_head</code> function to send the head of the request.</p>
<p>An example will illustrate this:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.host = 'foo.com'

def response_handler(resp): 
    print "Got a response: %s"% resp.status_code
request = client.put('/some-path', response_handler)

request.put_header('Expect', '100-Continue')
request.chunked = True

@request.continue_handler
def continue_handler():
    # OK to send rest of body

    request.write_str('Some data').end()

request.send_head()
</pre>
<h2 id="https-servers">HTTPS Servers</h2><br/>
<p>HTTPS servers are very easy to write using vert.x.</p>
<p>An HTTPS server has an identical API to a standard HTTP server. Getting the server to use HTTPS is just a matter of configuring the HTTP Server before <code>listen</code> is called.</p>
<p>Configuration of an HTTPS server is done in exactly the same way as configuring a <code>NetServer</code> for SSL. Please see the SSL server chapter for detailed instructions.</p>
<h2 id="https-clients">HTTPS Clients</h2><br/>
<p>HTTPS clients can also be very easily written with vert.x</p>
<p>Configuring an HTTP client for HTTPS is done in exactly the same way as configuring a <code>NetClient</code> for SSL. Please see the SSL client chapter for detailed instructions.</p>
<h2 id="scaling-http-servers">Scaling HTTP servers</h2><br/>
<p>Scaling an HTTP or HTTPS server over multiple cores is as simple as deploying more instances of the verticle. For example:</p>
<pre class="prettyprint">vertx deploy http_server.py -instances 20
</pre>
<p>The scaling works in the same way as scaling a <code>NetServer</code>. Please see the chapter on scaling Net Servers for a detailed explanation of how this works.</p>
<h1 id="routing-http-requests-with-pattern-matching">Routing HTTP requests with Pattern Matching</h1><br/>
<p>Vert.x lets you route HTTP requests to different handlers based on pattern matching on the request path. It also enables you to extract values from the path and use them as parameters in the request.</p>
<p>This is particularly useful when developing REST-style web applications.</p>
<p>To do this you simply create an instance of <code>core.http.RouteMatcher</code> and use it as handler in an HTTP server. See the chapter on HTTP servers for more information on setting HTTP handlers. Here's an example:</p>
<pre class="prettyprint">import vertx
from core.http import RouteMatcher

server = vertx.create_http_server()

route_matcher = RouteMatcher()

server.request_handler(route_matcher).listen(8080, 'localhost')
</pre>
<h2 id="specifying-matches">Specifying matches.</h2><br/>
<p>You can then add different matches to the route matcher. For example, to send all GET requests with path <code>/animals/dogs</code> to one handler and all GET requests with path <code>/animals/cats</code> to another handler you would do:</p>
<pre class="prettyprint">server = vertx.create_http_server()

route_matcher = RouteMatcher()

def dogs(req): req.response.end('You requested dogs')
route_matcher.get('/animals/dogs', dogs)

def cats(req): req.response.end('You requested cats')
route_matcher.get('/animals/cats', cats)

server.request_handler(route_matcher).listen(8080, 'localhost')
</pre>
<p>Corresponding methods exist for each HTTP method - <code>get</code>, <code>post</code>, <code>put</code>, <code>delete</code>, <code>head</code>, <code>options</code>, <code>trace</code>, <code>connect</code> and <code>patch</code>.</p>
<p>There's also an <code>all</code> method which applies the match to any HTTP request method.</p>
<p>The handler specified to the method is just a normal HTTP server request handler, the same as you would supply to the <code>request_handler</code> method of the HTTP server.</p>
<p>You can provide as many matches as you like and they are evaluated in the order you added them, the first matching one will receive the request.</p>
<p>A request is sent to at most one handler.</p>
<h2 id="extracting-parameters-from-the-path">Extracting parameters from the path</h2><br/>
<p>If you want to extract parameters from the path, you can do this too, by using the <code>:</code> (colon) character to denote the name of a parameter. For example:</p>
<pre class="prettyprint">server = vertx.create_http_server()

route_matcher = RouteMatcher()

def matched(req):
    blogName = req.params['blogname']
    post = req.params['post']
    req.response.end("blogname is %s post is %s" %(blogName, post))

route_matcher.put('/:blogname/:post', matched)

server.request_handler(route_matcher).listen(8080, 'localhost')
</pre>
<p>Any params extracted by pattern matching are added to the map of request parameters.</p>
<p>In the above example, a PUT request to <code>/myblog/post1</code> would result in the variable <code>blogName</code> getting the value <code>myblog</code> and the variable <code>post</code> getting the value <code>post1</code>.</p>
<p>Valid parameter names must start with a letter of the alphabet and be followed by any letters of the alphabet or digits.</p>
<h2 id="extracting-params-using-regular-expressions">Extracting params using Regular Expressions</h2><br/>
<p>Regular Expressions can be used to extract more complex matches. In this case capture groups are used to capture any parameters.</p>
<p>Since the capture groups are not named they are added to the request with names <code>param0</code>, <code>param1</code>, <code>param2</code>, etc.</p>
<p>Corresponding methods exist for each HTTP method - <code>get_re</code>, <code>post_re</code>, <code>put_re</code>, <code>delete_re</code>, <code>head_re</code>, <code>options_re</code>, <code>trace_re</code>, <code>connect_re</code> and <code>patch_re</code>.</p>
<p>There's also an <code>all_re</code> method which applies the match to any HTTP request method.</p>
<p>For example:</p>
<pre class="prettyprint">server = vertx.create_http_server()

route_matcher = RouteMatcher()

def matched(req):
    first = req.params['param0']
    second = req.params['param1']
    req.response.end("first is %s second is %s"% (first, second))

route_matcher.all_re("\/([^\/]+)\/([^\/]+)", matched)

server.request_handler(route_matcher).listen(8080, 'localhost')
</pre>
<p>Run the above and point your browser at <code>http://localhost:8080/animals/cats</code>.</p>
<p>It will display 'first is animals and second is cats'.    </p>
<h2 id="handling-requests-where-nothing-matches">Handling requests where nothing matches</h2><br/>
<p>You can use the <code>no_match</code> method to specify a handler that will be called if nothing matches. If you don't specify a no match handler and nothing matches, a 404 will be returned.</p>
<pre class="prettyprint">@route_matcher.no_match 
def no_match(req): req.response.end('Nothing matched')
</pre>
<h1 id="websockets">WebSockets</h1><br/>
<p><a href="http://en.wikipedia.org/wiki/WebSocket">WebSockets</a> are a feature of HTML 5 that allows a full duplex socket-like connection between HTTP servers and HTTP clients (typically browsers).</p>
<h2 id="websockets-on-the-server">WebSockets on the server</h2><br/>
<p>To use WebSockets on the server you create an HTTP server as normal, but instead of setting a <code>request_handler</code> you set a <code>websocket_handler</code> on the server.</p>
<pre class="prettyprint">server = Vertx::HttpServer.new

server.websocket_handler do |ws|

  # A WebSocket has connected!

end.listen(8080, 'localhost')
</pre>
<h3 id="reading-from-and-writing-to-websockets">Reading from and Writing to WebSockets</h3><br/>
<p>The <code>websocket</code> instance passed into the handler implements both <code>ReadStream</code> and <code>WriteStream</code>, so you can read and write data to it in the normal ways. I.e by setting a <code>data_handler</code> and calling the <code>write_buffer</code> and <code>write_str</code> methods.</p>
<p>See the chapter on <code>NetSocket</code> and streams and pumps for more information.</p>
<p>For example, to echo all data received on a WebSocket:</p>
<pre class="prettyprint">import vertx
from core.streams import Pump

server = vertx.create_http_server()

@server.websocket_handler 
def websocker_handler(websocket):
    p = new Pump(websocket, websocket)
    p.start()

server.listen(8080, 'localhost')
</pre>
<p>The <code>websocket</code> instance also has method <code>write_binary_frame</code> for writing binary data. This has the same effect as calling <code>write_buffer</code>.</p>
<p>Another method <code>write_text_frame</code> also exists for writing text data. This is equivalent to calling</p>
<pre class="prettyprint">websocket.write_buffer(Buffer.create('some-string'))
</pre>
<h3 id="rejecting-websockets">Rejecting WebSockets</h3><br/>
<p>Sometimes you may only want to accept WebSockets which connect at a specific path.</p>
<p>To check the path, you can query the <code>path</code> property of the <code>websocket</code>. You can then call the <code>reject</code> method to reject the websocket.</p>
<pre class="prettyprint">import vertx
from core.streams import Pump

server = vertx.create_http_server()

@server.websocket_handler 
def websocker_handler(websocket):

  if websocket.path == '/services/echo':
      p = Pump(websocket, websocket)
      p.start()
  else:
      websocket.reject()
server.listen(8080, 'localhost')
</pre>
<h2 id="websockets-on-the-http-client">WebSockets on the HTTP client</h2><br/>
<p>To use WebSockets from the HTTP client, you create the HTTP client as normal, then call the <code>connect_websocket</code> function, passing in the URI that you wish to connect to at the server, and a handler.</p>
<p>The handler will then get called if the WebSocket successfully connects. If the WebSocket does not connect - perhaps the server rejects it, then any exception handler on the HTTP client will be called.</p>
<p>Here's an example of WebSockets on the client:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.port = 8080

def websocket_handler(websocket):
    @websocket.data_handler
    def data_handler(buff): print "got %s"% buff

    websocket.write_text_frame('foo')

client.connect_web_socket('http://localhost:8080/services/echo', websocket_handler)
</pre>
<p>Again, the client side WebSocket implements <code>ReadStream</code> and <code>WriteStream</code>, so you can read and write to it in the same way as any other stream object.</p>
<h2 id="websockets-in-the-browser">WebSockets in the browser</h2><br/>
<p>To use WebSockets from a compliant browser, you use the standard WebSocket API. Here's some example client side JavaScript which uses a WebSocket.</p>
<pre class="prettyprint">&lt;script&gt;

    var socket = new WebSocket("ws://localhost:8080/services/echo");

    socket.onmessage = function(event) {
        alert("Received data from websocket: " + event.data);
    }

    socket.onopen = function(event) {
        alert("Web Socket opened");
        socket.send("Hello World");
    };

    socket.onclose = function(event) {
        alert("Web Socket closed");
    };

&lt;/script&gt;
</pre>
<p>For more information see the <a href="http://dev.w3.org/html5/websockets/">WebSocket API documentation</a></p>
<h2 id="routing-websockets-with-pattern-matching">Routing WebSockets with Pattern Matching</h2><br/>
<p><strong>TODO</strong></p>
<h1 id="sockjs">SockJS</h1><br/>
<p>WebSockets are a new technology, and many users are still using browsers that do not support them, or which support older, pre-final, versions.</p>
<p>Moreover, WebSockets do not work well with many corporate proxies. This means that's it's not possible to guarantee a WebSocket connection is going to succeed for every user.</p>
<p>Enter SockJS.</p>
<p>SockJS is a client side JavaScript library and protocol which provides a simple WebSocket-like interface to the client side JavaScript developer irrespective of whether the actual browser or network will allow real WebSockets.</p>
<p>It does this by supporting various different transports between browser and server, and choosing one at runtime according to browser and network capabilities. All this is transparent to you - you are simply presented with the WebSocket-like interface which <em>just works</em>.</p>
<p>Please see the <a href="https://github.com/sockjs/sockjs-client">SockJS website</a> for more information.</p>
<h2 id="sockjs-server">SockJS Server</h2><br/>
<p>Vert.x provides a complete server side SockJS implementation.</p>
<p>This enables vert.x to be used for modern, so-called <em>real-time</em> (this is the <em>modern</em> meaning of <em>real-time</em>, not to be confused by the more formal pre-existing definitions of soft and hard real-time systems) web applications that push data to and from rich client-side JavaScript applications, without having to worry about the details of the transport.</p>
<p>To create a SockJS server you simply create a HTTP server as normal and pass it in to the constructor of the SockJS server.</p>
<pre class="prettyprint">httpServer = vertx.create_http_server()

sockJSServer = vertx.create_sockjs_server(httpServer)
</pre>
<p>Each SockJS server can host multiple <em>applications</em>.</p>
<p>Each application is defined by some configuration, and provides a handler which gets called when incoming SockJS connections arrive at the server.</p>
<p>For example, to create a SockJS echo application:</p>
<pre class="prettyprint">import vertx
from core.streams import Pump

httpServer = vertx.create_http_server()

sockJSServer = vertx.create_sockjs_server(httpServer)

config = { 'prefix' : '/echo' }

def connect_handler(sock):
    p = Pump(sock, sock)
    p.start()
sockJSServer.install_app(config, connect_hander)

httpServer.listen(8080)
</pre>
<p>The configuration can take the following fields:</p>
<ul>
<li><code>prefix</code>: A url prefix for the application. All http requests whose paths begins with selected prefix will be handled by the application. This property is mandatory.</li>
<li><code>insert_JSESSIONID</code>: Some hosting providers enable sticky sessions only to requests that have JSESSIONID cookie set. This setting controls if the server should set this cookie to a dummy value. By default setting JSESSIONID cookie is enabled. More sophisticated beaviour can be achieved by supplying a function.</li>
<li><code>session_timeout</code>: The server sends a <code>close</code> event when a client receiving connection have not been seen for a while. This delay is configured by this setting. By default the <code>close</code> event will be emitted when a receiving connection wasn't seen for 5 seconds.</li>
<li><code>heartbeat_period</code>: In order to keep proxies and load balancers from closing long running http requests we need to pretend that the connecion is active and send a heartbeat packet once in a while. This setting controlls how often this is done. By default a heartbeat packet is sent every 25 seconds.</li>
<li><code>max_bytes_streaming</code>: Most streaming transports save responses on the client side and don't free memory used by delivered messages. Such transports need to be garbage-collected once in a while. <code>max_bytes_streaming</code> sets a minimum number of bytes that can be send over a single http streaming request before it will be closed. After that client needs to open new request. Setting this value to one effectively disables streaming and will make streaming transports to behave like polling transports. The default value is 128K.</li>
<li><code>library_url</code>: Transports which don't support cross-domain communication natively ('eventsource' to name one) use an iframe trick. A simple page is served from the SockJS server (using its foreign domain) and is placed in an invisible iframe. Code run from this iframe doesn't need to worry about cross-domain issues, as it's being run from domain local to the SockJS server. This iframe also does need to load SockJS javascript client library, and this option lets you specify its url (if you're unsure, point it to the latest minified SockJS client release, this is the default). The default value is <code>http://cdn.sockjs.org/sockjs-0.1.min.js</code></li>
</ul>
<h2 id="reading-and-writing-data-from-a-sockjs-server">Reading and writing data from a SockJS server</h2><br/>
<p>The object passed into the SockJS handler implements <code>ReadStream</code> and <code>WriteStream</code> much like <code>NetSocket</code> or <code>WebSocket</code>. You can therefore use the standard API for reading and writing to the SockJS socket or using it in pumps. See the chapter on Streams and Pumps for more information.</p>
<pre class="prettyprint">import vertx
from core.streams import Pump

httpServer = vertx.create_http_server()

sockJSServer = vertx.create_sockjs_server(httpServer)

config = { 'prefix' : '/echo' }

def connect_handler(sock):
    @sock.data_handler
    def data_handler(buffer):
        sock.write_buffer(fuffer)
sockJSServer.install_app(config, connect_hander)

httpServer.listen(8080)
</pre>
<h2 id="sockjs-client">SockJS client</h2><br/>
<p>For full information on using the SockJS client library please see the SockJS website. A simple example:</p>
<pre class="prettyprint">&lt;script&gt;
   var sock = new SockJS('http://mydomain.com/my_prefix');

   sock.onopen = function() {
       console.log('open');
   };

   sock.onmessage = function(e) {
       console.log('message', e.data);
   };

   sock.onclose = function() {
       console.log('close');
   };
&lt;/script&gt;
</pre>
<p>As you can see the API is very similar to the WebSockets API.    </p>
<h1 id="sockjs-eventbus-bridge">SockJS - EventBus Bridge</h1><br/>
<h2 id="setting-up-the-bridge">Setting up the Bridge</h2><br/>
<p>By connecting up SockJS and the vert.x event bus we create a distributed event bus which not only spans multiple vert.x instances on the server side, but can also include client side JavaScript running in browsers.</p>
<p>We can therefore create a huge distributed bus encompassing many browsers and servers. The browsers don't have to be connected to the same server as long as the servers are connected.</p>
<p>On the server side we have already discussed the event bus API.</p>
<p>We also provide a client side JavaScript library called <code>vertxbus.js</code> which provides the same event bus API, but on the client side.</p>
<p>This library internally uses SockJS to send and receive data to a SockJS vert.x server called the SockJS bridge. It's the bridge's responsibility to bridge data between SockJS sockets and the event bus on the server side.</p>
<p>Creating a Sock JS bridge is simple. You just call the <code>bridge</code> method on the SockJS server instance.</p>
<p>You will also need to secure the bridge (see below).</p>
<p>The following example creates and starts a SockJS bridge which will bridge any events sent to the path <code>eventbus</code> on to the server side event bus.</p>
<pre class="prettyprint">server = vertx.create_http_server()

sockJSServer = create_sockjs_server(server)

sockJSServer.bridge({'prefix' : '/eventbus'}, [], [])

server.listen(8080)
</pre>
<p>The SockJS bridge currently only works with JSON event bus messages.</p>
<h2 id="using-the-event-bus-from-client-side-javascript">Using the Event Bus from client side JavaScript</h2><br/>
<p>Once you've set up a bridge, you can use the event bus from the client side as follows:</p>
<p>In your web page, you need to load the script <code>vertxbus.js</code>, then you can access the vert.x event bus API. Here's a rough idea of how to use it. For a full working examples, please consult the bundled examples.</p>
<pre class="prettyprint">&lt;script src="http://cdn.sockjs.org/sockjs-0.2.1.min.js"&gt;&lt;/script&gt;
&lt;script src='vertxbus.js'&gt;&lt;/script&gt;

&lt;script&gt;

    var eb = new vertx.EventBus('http://localhost:8080/eventbus');

    eb.onopen = function() {

      eb.registerHandler('some-address', function(message) {

        console.log('received a message: ' + JSON.stringify(message);

      });

      eb.send('some-address', {name: 'tim', age: 587});

    }

&lt;/script&gt;
</pre>
<p>You can now communicate seamlessly between different browsers and server side components using the event bus [Read the section on securing the bridge!]</p>
<p>You can find <code>vertxbus.js</code> in the <code>client</code> directory of the vert.x distribution.</p>
<p>The first thing the example does is to create a instance of the event bus</p>
<pre class="prettyprint">var eb = new vertx.EventBus('http://localhost:8080/eventbus');
</pre>
<p>The parameter to the constructor is the URI where to connect to the event bus. Since we create our bridge with the prefix <code>eventbus</code> we will connect there.</p>
<p>You can't actually do anything with the bridge until it is opened. When it is open the <code>onopen</code> handler will be called.</p>
<p>The client side event bus API for registering and unregistering handlers and for sending messages is exactly the same as the server side one. Please consult the JavaScript core manual chapter on the EventBus for a description of that API.</p>
<h2 id="securing-the-bridge">Securing the Bridge</h2><br/>
<p>If you started a bridge like in the above example without securing it, and attempted to send messages through it you'd find that the messages mysteriously disappeared. What happened to them?</p>
<p>For most applications you probably don't want client side JavaScript being able to send just any message to any verticle on the server side or to all other browsers.</p>
<p>For example, you may have a persistor verticle on the event bus which allows data to be accessed or deleted. We don't want badly behaved or malicious clients being able to delete all the data in your database! Also, we don't necessarily want any client to be able to listen in on any topic.</p>
<p>To deal with this, a SockJS bridge will, by default refuse to let through any messages. It's up to you to tell the bridge what messages are ok for it to pass through. (There is an exception for reply messages which are always allowed through).</p>
<p>In other words the bridge acts like a kind of firewall which has a default <em>deny-all</em> policy.</p>
<p>Configuring the bridge to tell it what messages it should pass through is easy. You pass in two arrays of JSON objects that represent <em>matches</em>, as the final argument in the call to <code>bridge</code>.</p>
<p>The first array is the <em>inbound</em> list and represents the messages that you want to allow through from the client to the server. The second array is the <em>outbound</em> list and represents the messages that you want to allow through from the server to the client.</p>
<p>Each match can have up to three fields:</p>
<ol>
<li><code>address</code>: This represents the exact address the message is being sent to. If you want to filter messages based on an exact address you use this field.</li>
<li><code>address_re</code>: This is a regular expression that will be matched against the address. If you want to filter messages based on a regular expression you use this field. If the <code>address</code> field is specified this field will be ignored.</li>
<li><code>match</code>: This allows you to filter messages based on their structure. Any fields in the match must exist in the message with the same values for them to be passed. This currently only works with JSON messages.</li>
</ol>
<p>When a message arrives at the bridge, it will look through the available permitted entries.</p>
<ul>
<li>
<p>If an <code>address</code> field has been specified then the <code>address</code> must match exactly with the address of the message for it to be considered matched.</p>
</li>
<li>
<p>If an <code>address</code> field has not been specified and an <code>address_re</code> field has been specified then the regular expression in <code>address_re</code> must match with the address of the message for it to be considered matched.</p>
</li>
<li>
<p>If a <code>match</code> field has been specified, then also the structure of the message must match.</p>
</li>
</ul>
<p>Here is an example:</p>
<pre class="prettyprint">server = vertx.create_http_server()

sockJSServer = vertx.create_sockjs_server(server)

sockJSServer.bridge({'prefix' : '/eventbus'},
  [
    # Let through any messages sent to 'demo.orderMgr'
    {
      'address' : 'demo.orderMgr'
    },
    # Allow calls to the address 'demo.persistor' as long as the messages
    # have an action field with value 'find' and a collection field with value
    # 'albums'
    {
      'address' : 'demo.persistor',
      'match' : {
        'action' : 'find',
        'collection' : 'albums'
      }
    },
    # Allow through any message with a field `wibble` with value `foo`.
    {
      'match' : {
        'wibble' : 'foo'
      }
    }
  ], [{}])

server.listen(8080)
</pre>
<p>To let all messages through you can specify two arrays with a single empty JSON object which will match all messages.</p>
<pre class="prettyprint"> sockJSServer.bridge({'prefix' : '/eventbus'}, [{}], [{}])
</pre>
<p><strong>Be very careful!</strong></p>
<h2 id="messages-that-require-authorisation">Messages that require authorisation</h2><br/>
<p>The bridge can also refuse to let certain messages through if the user is not authorised.</p>
<p>To enable this you need to make sure an instance of the <code>vertx.auth-mgr</code> module is available on the event bus. (Please see the modules manual for a full description of modules).</p>
<p>To tell the bridge that certain messages require authorisation before being passed, you add the field <code>requires_auth</code> with the value of <code>true</code> in the match. The default value is <code>false</code>. For example, the following match:</p>
<pre class="prettyprint">{
  'address' : 'demo.persistor',
  'match' : {
    'action' : 'find',
    'collection' : 'albums'
  },
  'requires_auth` : true
}
</pre>
<p>This tells the bridge that any messages to save orders in the <code>orders</code> collection, will only be passed if the user is successful authenticated (i.e. logged in ok) first.    </p>
<p>When a message is sent from the client that requires authorisation, the client must pass a field <code>sessionID</code> with the message that contains the unique session ID that they obtained when they logged in with the <code>auth-mgr</code>.</p>
<p>When the bridge receives such a message, it will send a message to the <code>auth-mgr</code> to see if the session is authorised for that message. If the session is authorised the bridge will cache the authorisation for a certain amount of time (five minutes by default)</p>
<h1 id="file-system">File System</h1><br/>
<p>Vert.x lets you manipulate files on the file system. File system operations are asynchronous and take a handler block as the last argument.</p>
<p>This block will be called when the operation is complete, or an error has occurred.</p>
<p>The first argument passed into the block is an exception, if an error occurred. This will be <code>nil</code> if the operation completed successfully. If the operation returns a result that will be passed in the second argument to the handler.</p>
<h2 id="synchronous-forms">Synchronous forms</h2><br/>
<p>For convenience, we also provide synchronous forms of most operations. It's highly recommended the asynchronous forms are always used for real applications.</p>
<p>The synchronous form does not take a handler as an argument and returns its results directly. The name of the synchronous function is the same as the name as the asynchronous form with <code>_sync</code> appended.</p>
<h2 id="copy">copy</h2><br/>
<p>Copies a file.</p>
<p>This function can be called in two different ways:</p>
<ul>
<li><code>copy(source, destination)</code></li>
</ul>
<p>Non recursive file copy. <code>source</code> is the source file name. <code>destination</code> is the destination file name.</p>
<p>Here's an example:</p>
<pre class="prettyprint">from core.file_system import FileSystem

def handler(err, res):
    if not err: print 'Copy was successful'         
FileSystem.copy('foo.dat', 'bar.dat', handler
</pre>
<ul>
<li><code>copy(source, destination, recursive)</code></li>
</ul>
<p>Recursive copy. <code>source</code> is the source file name. <code>destination</code> is the destination file name. <code>recursive</code> is a boolean flag - if <code>true</code> and source is a directory, then a recursive copy of the directory and all its contents will be attempted.</p>
<h2 id="move">move</h2><br/>
<p>Moves a file.</p>
<p><code>move(source, destination)</code></p>
<p><code>source</code> is the source file name. <code>destination</code> is the destination file name.</p>
<h2 id="truncate">truncate</h2><br/>
<p>Truncates a file.</p>
<p><code>truncate(file, len)</code></p>
<p><code>file</code> is the file name of the file to truncate. <code>len</code> is the length in bytes to truncate it to.</p>
<h2 id="chmod">chmod</h2><br/>
<p>Changes permissions on a file or directory.</p>
<p>This function can be called in two different ways:</p>
<ul>
<li><code>chmod(file, perms)</code>.</li>
</ul>
<p>Change permissions on a file.</p>
<p><code>file</code> is the file name. <code>perms</code> is a Unix style permissions string made up of 9 characters. The first three are the owner's permissions. The second three are the group's permissions and the third three are others permissions. In each group of three if the first character is <code>r</code> then it represents a read permission. If the second character is <code>w</code>  it represents write permission. If the third character is <code>x</code> it represents execute permission. If the entity does not have the permission the letter is replaced with <code>-</code>. Some examples:</p>
<pre class="prettyprint">rwxr-xr-x
r--r--r--
</pre>
<ul>
<li><code>chmod(file, perms, dir_perms)</code>.</li>
</ul>
<p>Recursively change permissions on a directory. <code>file</code> is the directory name. <code>perms</code> is a Unix style permissions to apply recursively to any files in the directory. <code>dir_perms</code> is a Unix style permissions string to apply to the directory and any other child directories recursively.</p>
<h2 id="props">props</h2><br/>
<p>Retrieve properties of a file.</p>
<p><code>props(file)</code></p>
<p><code>file</code> is the file name. The props are returned in the handler. The results is an object with the following properties/methods:</p>
<ul>
<li><code>creation_time</code>: Time of file creation.</li>
<li><code>last_access_time</code>: Time of last file access.</li>
<li><code>last_modified_time</code>: Time file was last modified.</li>
<li><code>directory</code>: This will have the value <code>True</code> if the file is a directory.</li>
<li><code>regular_file</code>: This will have the value <code>True</code> if the file is a regular file (not symlink or directory).</li>
<li><code>symbolic_link</code>: This will have the value <code>True</code> if the file is a symbolic link.</li>
<li><code>other</code>: This will have the value <code>True</code> if the file is another type.</li>
</ul>
<p>Here's an example:</p>
<pre class="prettyprint">def props_handler(err, props):
    if err:
        print "Failed to retrieve file props: %s"% err
    else:
        print 'File props are:'
        print "Last accessed: %s"% props.lastAccessTime
        // etc

FileSystem.props('some-file.txt', props_handler)
</pre>
<h2 id="lprops">lprops</h2><br/>
<p>Retrieve properties of a link. This is like <code>props</code> but should be used when you want to retrieve properties of a link itself without following it.</p>
<p>It takes the same arguments and provides the same results as <code>props</code>.</p>
<h2 id="link">link</h2><br/>
<p>Create a hard link.</p>
<p><code>link(link, existing)</code></p>
<p><code>link</code> is the name of the link. <code>existing</code> is the existing file (i.e. where to point the link at).</p>
<h2 id="symlink">symlink</h2><br/>
<p>Create a symbolic link.</p>
<p><code>sym_link(link, existing)</code></p>
<p><code>link</code> is the name of the symlink. <code>existing</code> is the existing file (i.e. where to point the symlink at).</p>
<h2 id="unlink">unlink</h2><br/>
<p>Unlink (delete) a link.</p>
<p><code>unlink(link)</code></p>
<p><code>link</code> is the name of the link to unlink.</p>
<h2 id="read_sym_link">read_sym_link</h2><br/>
<p>Reads a symbolic link. I.e returns the path representing the file that the symbolic link specified by <code>link</code> points to.</p>
<p><code>read_sym_link(link)</code></p>
<p><code>link</code> is the name of the link to read. An usage example would be:</p>
<pre class="prettyprint">def handler(err, res):
    if not err: print "Link points at %s"% res
Vertx::FileSystem.read_sym_link('somelink', handler)
</pre>
<h2 id="delete">delete</h2><br/>
<p>Deletes a file or recursively deletes a directory.</p>
<p>This function can be called in two ways:</p>
<ul>
<li><code>delete(file)</code></li>
</ul>
<p>Deletes a file. <code>file</code> is the file name.</p>
<ul>
<li><code>delete(file, recursive)</code></li>
</ul>
<p>If <code>recursive</code> is <code>true</code>, it deletes a directory with name <code>file</code>, recursively. Otherwise it just deletes a file.</p>
<h2 id="mkdir">mkdir</h2><br/>
<p>Creates a directory.</p>
<p>This function can be called in three ways:</p>
<ul>
<li><code>mkdir(dirname)</code></li>
</ul>
<p>Makes a new empty directory with name <code>dirname</code>, and default permissions `</p>
<ul>
<li><code>mkdir(dirname, create_parents)</code></li>
</ul>
<p>If <code>create_parents</code> is <code>true</code>, this creates a new directory and creates any of its parents too. Here's an example</p>
<pre class="prettyprint">def handler(err, res):
    if not err: print "Directory created ok"
FileSystem.mkdir('a/b/c', True, handler=handler)
</pre>
<ul>
<li><code>mkdir(dirname, create_parents, perms)</code></li>
</ul>
<p>Like <code>mkdir(dirname, create_parents, handler)</code>, but also allows permissions for the newly created director(ies) to be specified. <code>perms</code> is a Unix style permissions string as explained earlier.</p>
<h2 id="read_dir">read_dir</h2><br/>
<p>Reads a directory. I.e. lists the contents of the directory.</p>
<p>This method can be called in two ways:</p>
<ul>
<li><code>read_dir(dir_name)</code></li>
</ul>
<p>Lists the contents of a directory</p>
<ul>
<li><code>read_dir(dir_name, filter)</code></li>
</ul>
<p>List only the contents of a directory which match the filter. Here's an example which only lists files with an extension <code>txt</code> in a directory.</p>
<pre class="prettyprint">def handler(err,res):
    if not err:
        print 'Directory contains these .txt files'
        @res.each
        def each(filename):
            print filename
FileSystem.read_dir('mydirectory', '.*\.txt', handler)
</pre>
<p>The filter is a regular expression.    </p>
<h2 id="read_file_as_buffer">read_file_as_buffer</h2><br/>
<p>Read the entire contents of a file in one go. <em>Be careful if using this with large files since the entire file will be stored in memory at once</em>.</p>
<p><code>read_file_as_bufer(file)</code>. Where <code>file</code> is the file name of the file to read.</p>
<p>The body of the file will be returned as a <code>Buffer</code> in the handler.</p>
<p>Here is an example:</p>
<pre class="prettyprint">def handler(err,res):
    if not err: "File contains: %s bytes"% res.length
FileSystem.read_file_as_buffer('myfile.dat', handler)
</pre>
<h2 id="write_buffer_to_file">write_buffer_to_file</h2><br/>
<p>Writes an entire <code>Buffer</code> into a new file on disk</p>
<p><code>write_buffer_to_file(file, data)</code> Where <code>file</code> is the file name. <code>data</code> is a <code>Buffer</code> or string.</p>
<h2 id="create_file">create_file</h2><br/>
<p>Creates a new empty file.</p>
<p><code>create_file(file)</code>. Where <code>file</code> is the file name.</p>
<h2 id="exists">exists?</h2><br/>
<p>Checks if a file exists.</p>
<p><code>exists(file)</code>. Where <code>file</code> is the file name.</p>
<p>The result is returned in the handler.</p>
<pre class="prettyprint">def handler(err,res):
    if not err:
        if res: print 'exists'
        else: print 'does not exist'
FileSystem.exists('some-file.txt', handler)
</pre>
<h2 id="fs_props">fs_props</h2><br/>
<p>Get properties for the file system.</p>
<p><code>fs_props(file)</code>. Where <code>file</code> is any file on the file system.</p>
<p>The result is returned in the handler. The result object has the following fields:</p>
<ul>
<li><code>total_space</code>. Total space on the file system in bytes.</li>
<li><code>unallocated_space</code>. Unallocated space on the file system in bytes.</li>
<li><code>usable_space</code>. Usable space on the file system in bytes.</li>
</ul>
<p>Here is an example:</p>
<pre class="prettyprint">def handler(err,res):
    if not err: print "total space: %s"% res.total_space
FileSystem.fs_props('mydir', handler)
</pre>
<h2 id="open">open</h2><br/>
<p>Opens an asynchronous file for reading \ writing.</p>
<ul>
<li><code>open(path, perms = None, read = True, write = True, create_new = True, flush = False)</code></li>
</ul>
<p>When the file is opened, an instance of <code>AsyncFile</code> is passed into the result handler block:</p>
<pre class="prettyprint">def handler(err, file):
    if err:
        print "Failed to open file ", err
    else:
        print 'File opened ok'
        file.close()
FileSystem.open('some-file.dat', handler=handler)
</pre>
<p>If <code>read</code> is <code>True</code>, the file will be opened for reading. If <code>write</code> is <code>True</code> the file will be opened for writing. If <code>create_new</code> is <code>True</code>, the file will be created if it doesn't already exist. If <code>flush</code> is <code>True</code> then every write on the file will be automatically flushed (synced) from the OS cache.  <br/>
If the file is created, <code>perms</code> is a Unix-style permissions string used to describe the file permissions for the newly created file.</p>
<h2 id="asyncfile">AsyncFile</h2><br/>
<p>Instances of <code>AsyncFile</code> are returned from calls to <code>open</code> and you use them to read from and write to files asynchronously. They allow asynchronous random file access.</p>
<p>AsyncFile can provide instances of <code>ReadStream</code> and <code>WriteStream</code> via the <code>getReadStream</code> and <code>getWriteStream</code> functions, so you can pump files to and from other stream objects such as net sockets, http requests and responses, and WebSockets.</p>
<p>They also allow you to read and write directly to them.</p>
<h3 id="random-access-writes">Random access writes</h3><br/>
<p>To use an AsyncFile for random access writing you use the <code>write</code> method.</p>
<p><code>write(buffer, position, handler)</code>.</p>
<p>The parameters to the method are: </p>
<ul>
<li><code>buffer</code>: the buffer to write.</li>
<li><code>position</code>: an integer position in the file where to write the buffer. If the position is greater or equal to the size of the file, the file will be enlarged to accomodate the offset.</li>
<li><code>block</code>: a block to call when the operation is complete.</li>
</ul>
<p>Here is an example of random access writes:</p>
<pre class="prettyprint">def handler(err, async_file):
    if err:
        print "Failed to open file ",err
    else:
        # File open, write a buffer 5 times into a file
        buff = Buffer.create('foo')
        for i in range(1, 6):
            def write_handler(err, res):          
                if err:
                    print "Failed to write ", err
                else:
                    print 'Written ok'  
            async_file.write(buff, buff.length() * i, write_handler)

FileSystem.open('some-file.dat', handler=handler)
</pre>
<h3 id="random-access-reads">Random access reads</h3><br/>
<p>To use an AsyncFile for random access reads you use the <code>read</code> method.</p>
<p><code>read(buffer, offset, position, length, handler)</code>.</p>
<p>The parameters to the method are: </p>
<ul>
<li><code>buffer</code>: the buffer into which the data will be read.</li>
<li><code>offset</code>: an integer offset into the buffer where the read data will be placed.</li>
<li><code>position</code>: the position in the file where to read data from.</li>
<li><code>length</code>: the number of bytes of data to read</li>
<li><code>block</code>: a block to call when the operation is complete.</li>
</ul>
<p>Here's an example of random access reads:</p>
<pre class="prettyprint">def open_handler(err, async_file):
    if err:
        print "Failed to open file ", err
    else:
        buff = Buffer.create(1000)
        for i in range(1,11):
            def read_handler(err, res):
                if err:
                    print "Failed to read ", err
                else:
                    print 'Read ok'
            async_file.read(buff, i * 100, i * 100, 100, read_handler)
FileSystem.open('some-file.dat', handler=open_handler)
</pre>
<h3 id="flushing-data-to-underlying-storage">Flushing data to underlying storage.</h3><br/>
<p>If the AsyncFile was not opened with <code>flush = true</code>, then you can manually flush any writes from the OS cache by calling the <code>flush</code> method.</p>
<h3 id="using-asyncfile-as-readstream-and-writestream">Using AsyncFile as <code>ReadStream</code> and <code>WriteStream</code></h3><br/>
<p>Use the methods <code>read_stream</code> and <code>write_stream</code> to get read and write streams. You can then use them with a pump to pump data to and from other read and write streams.</p>
<p>Here's an example of pumping data from a file on a client to a HTTP request:</p>
<pre class="prettyprint">client = vertx.create_http_client()
client.host = 'foo.com'

def open_handler(err, async_file):
    if err:
        print "Failed to open file ", err
    else:
        def handler(resp):
            print "resp status code %s"% resp.status_code
        request = client.put('/uploads', handler)

        rs = asyncFile.read_stream
        pump = Pump(rs, request)
        pump.start()
        @rs.end_handler
        def end_handler(): 
            # File sent, end HTTP requuest
            request.end()

FileSystem.open('some-file.dat', handler=open_handler)
</pre>
<h3 id="closing-an-asyncfile">Closing an AsyncFile</h3><br/>
<p>To close an AsyncFile call the <code>close</code> method. Closing is asynchronous and if you want to be notified when the close has been completed you can specify a handler block as an argument to <code>close</code>.</p></div>
      </div>
    </div>
  </div>

</div>

</body>
</html>
